# config.py
"""
åŒè‰²çƒåˆ†æç³»ç»Ÿ - é…ç½®æ–‡ä»¶ (å®é™…é…ç½®ç‰ˆ)
åŸºäºå®é™…é¡¹ç›®ç»“æ„è°ƒæ•´
"""

# =============================================================================
# å®é™…é¡¹ç›®ç»“æ„å›¾ (åŸºäºå®é™…è¿è¡Œæƒ…å†µ)
# =============================================================================
"""
double_ball_analyzer/
â”œâ”€â”€ config.py                    # é…ç½®ç®¡ç† (æœ¬æ–‡ä»¶)
â”œâ”€â”€ main.py                      # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ requirements.txt             # ä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ README.md                    # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ run.py                       # å¿«é€Ÿå¯åŠ¨è„šæœ¬
â”œâ”€â”€ data_sync.py                 # ç‹¬ç«‹æ•°æ®åŒæ­¥è„šæœ¬
â”‚
â”œâ”€â”€ core/                        # æ ¸å¿ƒç³»ç»Ÿæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ analyzer.py              # ä¸»åˆ†æå™¨
â”‚   â”œâ”€â”€ enhanced_analyzer.py     # å¢å¼ºåˆ†æå™¨
â”‚   â””â”€â”€ unified_analyzer.py      # ç»Ÿä¸€åˆ†ææ¥å£
â”‚
â”œâ”€â”€ data/                        # æ•°æ®æ¨¡å— (å®é™…æ•°æ®åº“ä½ç½®)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ database.py              # æ•°æ®åº“æ“ä½œ
â”‚   â”œâ”€â”€ crawler.py               # æ•°æ®çˆ¬å–
â”‚   â”œâ”€â”€ models.py                # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ processor.py             # åŸºç¡€æ•°æ®å¤„ç†
â”‚   â”œâ”€â”€ advanced_processor.py    # é«˜çº§ç‰¹å¾å¤„ç†
â”‚   â””â”€â”€ predictor.py             # é¢„æµ‹ç®—æ³•
â”‚
â”œâ”€â”€ analysis/                    # åˆ†ææ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ statistics.py            # ç»Ÿè®¡åˆ†æ
â”‚   â”œâ”€â”€ visualization.py         # æ•°æ®å¯è§†åŒ–
â”‚   â”œâ”€â”€ trend_analysis.py        # è¶‹åŠ¿åˆ†æ
â”‚   â”œâ”€â”€ probability_analyzer.py  # æ¦‚ç‡åˆ†æå™¨
â”‚   â””â”€â”€ hot_cold_analyzer.py     # çƒ­å†·å·åˆ†æå™¨
â”‚
â”œâ”€â”€ services/                    # æœåŠ¡æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ prediction_service.py    # é¢„æµ‹æœåŠ¡
â”‚   â”œâ”€â”€ analysis_service.py      # åˆ†ææœåŠ¡
â”‚   â”œâ”€â”€ model_training.py        # æ¨¡å‹è®­ç»ƒæœåŠ¡
â”‚   â””â”€â”€ export_service.py        # å¯¼å‡ºæœåŠ¡
â”‚
â”œâ”€â”€ ui/                          # ç”¨æˆ·ç•Œé¢æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ display.py               # æ˜¾ç¤ºç®¡ç†
â”‚   â”œâ”€â”€ interactive.py           # äº¤äº’ç®¡ç† (ä¸»ç•Œé¢)
â”‚   â””â”€â”€ menu.py                  # èœå•ç³»ç»Ÿ
â”‚
â”œâ”€â”€ utils/                       # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py                # æ—¥å¿—å·¥å…·
â”‚   â”œâ”€â”€ color_utils.py           # é¢œè‰²å·¥å…·
â”‚   â”œâ”€â”€ data_utils.py            # æ•°æ®å¤„ç†å·¥å…·
â”‚   â”œâ”€â”€ file_utils.py            # æ–‡ä»¶æ“ä½œå·¥å…·
â”‚   â”œâ”€â”€ db_manager.py            # æ•°æ®åº“ç®¡ç†å™¨
â”‚   â””â”€â”€ validation_utils.py      # éªŒè¯å·¥å…·
â”‚
â”œâ”€â”€ workflows/                   # å·¥ä½œæµç¨‹æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ full_analysis.py         # å®Œæ•´åˆ†ææµç¨‹
â”‚   â”œâ”€â”€ prediction_workflow.py   # é¢„æµ‹æµç¨‹
â”‚   â””â”€â”€ data_pipeline.py         # æ•°æ®å¤„ç†æµç¨‹
â”‚
â”œâ”€â”€ data/                        # æ•°æ®æ–‡ä»¶ç›®å½• (å®é™…ä½ç½®)
â”‚   â””â”€â”€ double_ball.db          # ä¸»æ•°æ®åº“æ–‡ä»¶ (å®é™…ä½ç½®)
â”‚
â”œâ”€â”€ reports/                     # æŠ¥å‘Šæ–‡ä»¶ç›®å½• (å®é™…ä½ç½®)
â”‚   â”œâ”€â”€ prediction_*.txt        # é¢„æµ‹æŠ¥å‘Š
â”‚   â””â”€â”€ analysis_*.txt          # åˆ†ææŠ¥å‘Š
â”‚
â”œâ”€â”€ visualizations/              # å¯è§†åŒ–å›¾è¡¨ç›®å½•
â”‚   â”œâ”€â”€ red_frequency.png
â”‚   â”œâ”€â”€ blue_frequency.png
â”‚   â””â”€â”€ time_series.png
â”‚
â”œâ”€â”€ logs/                       # æ—¥å¿—æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ double_ball.log
â”‚   â”œâ”€â”€ crawler.log
â”‚   â””â”€â”€ prediction.log
â”‚
â”œâ”€â”€ exports/                    # å¯¼å‡ºæ–‡ä»¶ç›®å½• (æ–°å¢)
â”‚   â”œâ”€â”€ csv_exports/
â”‚   â”œâ”€â”€ json_exports/
â”‚   â””â”€â”€ excel_exports/
â”‚
â”œâ”€â”€ models/                     # æ¨¡å‹æ–‡ä»¶ç›®å½• (è¿è¡Œæ—¶åˆ›å»º)
â”‚   â”œâ”€â”€ xgboost_model.pkl
â”‚   â”œâ”€â”€ lightgbm_model.pkl
â”‚   â””â”€â”€ statistical_model.pkl
â”‚
â””â”€â”€ tests/                      # æµ‹è¯•ç›®å½• (å¯é€‰)
    â””â”€â”€ __init__.py

å®é™…ä½¿ç”¨çš„ç›®å½•ç»“æ„ (é‡ç‚¹)ï¼š
1. data/double_ball.db      - æ•°æ®åº“æ–‡ä»¶ (å®é™…ä½ç½®ï¼Œä¿æŒä¸å˜)
2. reports/                 - æŠ¥å‘Šæ–‡ä»¶ (å®é™…ä½ç½®ï¼Œä¿æŒä¸å˜)
3. visualizations/          - å¯è§†åŒ–å›¾è¡¨
4. logs/                   - æ—¥å¿—æ–‡ä»¶
5. exports/                - å¯¼å‡ºæ–‡ä»¶ (æ–°å¢)
6. models/                 - æ¨¡å‹æ–‡ä»¶

æ¨¡å—ä¾èµ–å…³ç³»:
main.py â†’ config.py â†’ core/ â†’ services/ â†’ analysis/ â†’ data/ â†’ ui/ â†’ workflows/ â†’ utils/
æ•°æ®å¤„ç†æµç¨‹: çˆ¬å–æ•°æ® â†’ å­˜å‚¨åˆ°æ•°æ®åº“ â†’ åŸºç¡€æ•°æ®å¤„ç† â†’ é«˜çº§ç‰¹å¾å¤„ç† â†’ ç»Ÿè®¡åˆ†æ â†’ å¯è§†åŒ–å±•ç¤º â†’ é¢„æµ‹åˆ†æ â†’ æŠ¥å‘Šç”Ÿæˆ
"""

import os
import logging
import yaml
from typing import Dict, Any, List, Tuple, Optional
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path

@dataclass
class PathConfig:
    """è·¯å¾„é…ç½® (åŸºäºå®é™…é¡¹ç›®ç»“æ„)"""

    # åŸºç¡€è·¯å¾„
    BASE_DIR: str = os.path.dirname(os.path.abspath(__file__))

    # æ ¸å¿ƒæ¨¡å—è·¯å¾„
    CORE_DIR: str = os.path.join(BASE_DIR, 'core')
    DATA_DIR: str = os.path.join(BASE_DIR, 'data')
    ANALYSIS_DIR: str = os.path.join(BASE_DIR, 'analysis')
    SERVICES_DIR: str = os.path.join(BASE_DIR, 'services')
    UI_DIR: str = os.path.join(BASE_DIR, 'ui')
    UTILS_DIR: str = os.path.join(BASE_DIR, 'utils')
    WORKFLOWS_DIR: str = os.path.join(BASE_DIR, 'workflows')

    # æ•°æ®æ–‡ä»¶è·¯å¾„ (åŸºäºå®é™…ä½ç½®)
    DATABASE_PATH: str = os.path.join(DATA_DIR, 'double_ball.db')  # å®é™…æ•°æ®åº“ä½ç½®
    BACKUP_DIR: str = os.path.join(DATA_DIR, 'backups')           # æ•°æ®åº“å¤‡ä»½ç›®å½•
    CACHE_DIR: str = os.path.join(DATA_DIR, 'cache')              # ç¼“å­˜ç›®å½•
    
    # æŠ¥å‘Šæ–‡ä»¶è·¯å¾„ (åŸºäºå®é™…ä½ç½® - æ ¹ç›®å½•ä¸‹çš„reports)
    REPORTS_DIR: str = os.path.join(BASE_DIR, 'reports')          # å®é™…æŠ¥å‘Šä½ç½®
    
    # å¯¼å‡ºæ–‡ä»¶è·¯å¾„ (æ–°å¢)
    EXPORTS_DIR: str = os.path.join(BASE_DIR, 'exports')
    
    # å¯è§†åŒ–æ–‡ä»¶è·¯å¾„
    VISUALIZATIONS_DIR: str = os.path.join(BASE_DIR, 'visualizations')
    
    # æ¨¡å‹æ–‡ä»¶è·¯å¾„
    MODELS_DIR: str = os.path.join(BASE_DIR, 'models')
    
    # æ—¥å¿—æ–‡ä»¶è·¯å¾„
    LOGS_DIR: str = os.path.join(BASE_DIR, 'logs')
    MAIN_LOG: str = os.path.join(LOGS_DIR, 'double_ball.log')
    CRAWLER_LOG: str = os.path.join(LOGS_DIR, 'crawler.log')
    PREDICTION_LOG: str = os.path.join(LOGS_DIR, 'prediction.log')
    
    # æµ‹è¯•è·¯å¾„ (å¯é€‰)
    TESTS_DIR: str = os.path.join(BASE_DIR, 'tests')

    def __post_init__(self):
        """åˆå§‹åŒ–å®é™…ä½¿ç”¨çš„ç›®å½•ç»“æ„"""
        directories = [
            # ä»£ç ç›®å½•
            self.CORE_DIR, self.DATA_DIR, self.ANALYSIS_DIR,
            self.SERVICES_DIR, self.UI_DIR, self.UTILS_DIR,
            self.WORKFLOWS_DIR,

            # æ•°æ®ç›®å½•
            self.BACKUP_DIR, self.CACHE_DIR,
            
            # æŠ¥å‘Šå’Œå¯¼å‡ºç›®å½• (å®é™…ä½¿ç”¨)
            self.REPORTS_DIR,         # æŠ¥å‘Šç›®å½• (å®é™…ä½¿ç”¨)
            self.EXPORTS_DIR,         # å¯¼å‡ºç›®å½• (æ–°å¢)
            
            # å¯è§†åŒ–ç›®å½•
            self.VISUALIZATIONS_DIR,
            
            # æ¨¡å‹ç›®å½•
            self.MODELS_DIR,
            
            # æ—¥å¿—ç›®å½•
            self.LOGS_DIR,
            
            # æµ‹è¯•ç›®å½• (å¯é€‰)
            self.TESTS_DIR
        ]

        for directory in directories:
            os.makedirs(directory, exist_ok=True)
            logging.debug(f"ç¡®ä¿ç›®å½•å­˜åœ¨: {directory}")

@dataclass
class DatabaseConfig:
    """æ•°æ®åº“é…ç½®"""
    
    # æ•°æ®åº“è®¾ç½®
    DATABASE_PATH: str = "data/double_ball.db"  # åŸºäºå®é™…ä½ç½®
    TABLE_NAME: str = "doubleball_records"
    
    # è¿æ¥è®¾ç½®
    TIMEOUT: int = 30
    CHECK_SAME_THREAD: bool = False
    AUTOMATIC_BACKUP: bool = True
    
    # å¤‡ä»½è®¾ç½®
    BACKUP_ENABLED: bool = True
    BACKUP_INTERVAL_DAYS: int = 7
    MAX_BACKUP_FILES: int = 10
    BACKUP_ON_START: bool = True
    
    # æ€§èƒ½è®¾ç½®
    CACHE_SIZE: int = 10000
    JOURNAL_MODE: str = "WAL"
    SYNC_MODE: str = "NORMAL"
    
    # æ•°æ®å®Œæ•´æ€§
    FOREIGN_KEYS: bool = True
    AUTO_VACUUM: bool = True
    
    # æŸ¥è¯¢ä¼˜åŒ–
    DEFAULT_LIMIT: int = 1000
    BATCH_SIZE: int = 100


@dataclass
class CrawlerConfig:
    """çˆ¬è™«é…ç½®"""

    # æ•°æ®æºé…ç½®
    DATA_SOURCES: Dict[str, str] = field(default_factory=lambda: {
        'primary': 'https://datachart.500.com/ssq/history/history.shtml',
        'backup_1': 'https://www.500.com/static/info/kaijiang/ssq/',
        'backup_2': 'https://kaijiang.zhcw.com'
    })

    # æ¯å¹´æœŸæ•°é…ç½®
    YEAR_ISSUES: Dict[int, int] = field(default_factory=lambda: {
        2003: 89, 2004: 122, 2005: 153, 2006: 154, 2007: 153,
        2008: 154, 2009: 154, 2010: 153, 2011: 153, 2012: 154,
        2013: 154, 2014: 152, 2015: 154, 2016: 153, 2017: 154,
        2018: 153, 2019: 151, 2020: 134, 2021: 150, 2022: 150,
        2023: 151, 2024: 151, 2025: 151, 2026: 151
    })

    # è¯·æ±‚é…ç½®
    USER_AGENT: str = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
    REQUEST_TIMEOUT: int = 30
    MAX_RETRIES: int = 3
    RETRY_DELAY: float = 1.0
    RETRY_BACKOFF: float = 2.0

    # å»¶è¿Ÿé…ç½®
    REQUEST_DELAY: Tuple[float, float] = (1.0, 3.0)  # æœ€å°å’Œæœ€å¤§å»¶è¿Ÿç§’æ•°

    # å¹¶å‘é…ç½®
    MAX_CONCURRENT_REQUESTS: int = 5
    CONCURRENT_DELAY: float = 0.5

    # æ•°æ®æ›´æ–°é…ç½®
    UPDATE_INTERVAL_HOURS: int = 6
    FORCE_UPDATE_DAYS: int = 1
    INCREMENTAL_UPDATE: bool = True

    # ä»£ç†é…ç½®
    USE_PROXY: bool = False
    PROXY_POOL: List[str] = field(default_factory=list)

    # æ•°æ®éªŒè¯
    VALIDATE_DATA: bool = True
    MIN_RECORDS_PER_YEAR: Dict[int, int] = field(default_factory=lambda: {
        2003: 80, 2004: 110, 2005: 140, 2006: 140, 2007: 140,
        2008: 140, 2009: 140, 2010: 140, 2011: 140, 2012: 140,
        2013: 140, 2014: 140, 2015: 140, 2016: 140, 2017: 140,
        2018: 140, 2019: 140, 2020: 120, 2021: 140, 2022: 140,
        2023: 140, 2024: 140, 2025: 140, 2026: 140
    })

@dataclass
class ProcessorConfig:
    """å¤„ç†å™¨é…ç½®"""
    
    # å¤„ç†å™¨å¯ç”¨é…ç½®
    PROCESSOR_ENABLED: bool = True
    ADVANCED_PROCESSOR_ENABLED: bool = True
    
    # ç‰¹å¾å¤„ç†é…ç½®
    HEAT_COLD_WINDOW: int = 15
    RECENT_ANALYSIS_WINDOW: int = 10
    TREND_ANALYSIS_WINDOW: int = 5
    OMISSION_HISTORY_WINDOW: int = 50
    
    # æ•°æ®éªŒè¯é…ç½®
    MIN_RED_BALL: int = 1
    MAX_RED_BALL: int = 33
    MIN_BLUE_BALL: int = 1
    MAX_BLUE_BALL: int = 16
    
    # ç‰¹å¾ç”Ÿæˆé…ç½®
    GENERATE_AC_VALUE: bool = True
    GENERATE_SUM_FEATURES: bool = True
    GENERATE_ZONE_FEATURES: bool = True
    GENERATE_INTERVAL_FEATURES: bool = True
    
    # ç¼“å­˜é…ç½®
    FEATURE_CACHE_SIZE: int = 1000
    CACHE_TTL_SECONDS: int = 3600
    
    # ç‰¹å¾é˜ˆå€¼
    HOT_THRESHOLD_MULTIPLIER: float = 1.5
    COLD_THRESHOLD_MULTIPLIER: float = 0.5

@dataclass
class AnalysisConfig:
    """åˆ†æé…ç½®"""
    
    # ç»Ÿè®¡åˆ†æé…ç½®
    STATISTICS_ENABLED: bool = True
    BASIC_STATS_WINDOW: int = 100  # é•¿æœŸ
    FREQUENCY_ANALYSIS_WINDOW: int = 50  # ä¸­æœŸ
    TREND_ANALYSIS_WINDOW: int = 30  # çŸ­æœŸ

    # ========== æ–°å¢ï¼šç»Ÿä¸€çª—å£é…ç½®ï¼ˆå…¼å®¹æ€§åˆ«åï¼‰ ==========
    # # ç»Ÿä¸€å‘½åï¼Œä¾¿äºä»£ç ç†è§£å’Œä½¿ç”¨
    # SHORT_TERM_WINDOW: int = 30  # é»˜è®¤å€¼ï¼Œå¦‚æœç”¨æˆ·æœªè®¾ç½®
    # MEDIUM_TERM_WINDOW: int = 50  # é»˜è®¤å€¼
    # LONG_TERM_WINDOW: int = 100  # é»˜è®¤å€¼
    # ALL_HISTORY_WINDOW: Any = None  # å…¨éƒ¨å†å²
    #
    # # çƒ­å†·å·åˆ†æçª—å£
    # HOT_COLD_WINDOW: int = None  # é»˜è®¤ä½¿ç”¨çŸ­æœŸçª—å£
    #
    # # è¶‹åŠ¿åˆ†æçª—å£é…ç½®
    # # TREND_WINDOW_SIZES: List[int] = field(default_factory=lambda: [30, 50, 100])
    # _TREND_WINDOW_SIZES: List[Optional[int]] = field(default_factory=lambda: [30, 50, 100, None])

    # def __post_init__(self):
    #     """
    #     åˆå§‹åŒ–åå¤„ç†ï¼š
    #     1. ç¡®ä¿æ–°æ—§é…ç½®ä¸€è‡´
    #     2. åŠ¨æ€è®¾ç½®è¶‹åŠ¿çª—å£
    #     """
    #     # ç¬¬ä¸€æ­¥ï¼šåŒæ­¥æ–°æ—§é…ç½®ï¼ˆç¡®ä¿å…¼å®¹æ€§ï¼‰
    #     # å¦‚æœç”¨æˆ·é€šè¿‡æ—§é…ç½®è®¾ç½®äº†å€¼ï¼Œæ›´æ–°æ–°é…ç½®
    #     if self.TREND_ANALYSIS_WINDOW != 30:  # ä¸æ˜¯é»˜è®¤å€¼
    #         self.SHORT_TERM_WINDOW = self.TREND_ANALYSIS_WINDOW
    #
    #     if self.FREQUENCY_ANALYSIS_WINDOW != 50:  # ä¸æ˜¯é»˜è®¤å€¼
    #         self.MEDIUM_TERM_WINDOW = self.FREQUENCY_ANALYSIS_WINDOW
    #
    #     if self.BASIC_STATS_WINDOW != 100:  # ä¸æ˜¯é»˜è®¤å€¼
    #         self.LONG_TERM_WINDOW = self.BASIC_STATS_WINDOW
    #
    #     # ç¬¬äºŒæ­¥ï¼šç¡®ä¿çƒ­å†·å·çª—å£æœ‰å€¼
    #     if self.HOT_COLD_WINDOW == 30:  # è¿˜æ˜¯é»˜è®¤å€¼
    #         self.HOT_COLD_WINDOW = self.SHORT_TERM_WINDOW
    #
    #     # ç¬¬ä¸‰æ­¥ï¼šåŠ¨æ€è®¾ç½®è¶‹åŠ¿çª—å£
    #     if self._TREND_WINDOW_SIZES == [30, 50, 100, None]:  # é»˜è®¤å€¼
    #         self._TREND_WINDOW_SIZES = [
    #             self.SHORT_TERM_WINDOW,
    #             self.MEDIUM_TERM_WINDOW,
    #             self.LONG_TERM_WINDOW,
    #             None
    #         ]
    #
    #     logger.debug(
    #         f"çª—å£é…ç½®åŒæ­¥å®Œæˆ: çŸ­æœŸ={self.SHORT_TERM_WINDOW}, ä¸­æœŸ={self.MEDIUM_TERM_WINDOW}, é•¿æœŸ={self.LONG_TERM_WINDOW}")

    # ========== æ–°å¢ï¼šç»Ÿä¸€çª—å£é…ç½® ==========
    # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨field(default_factory)ç¡®ä¿æ¯ä¸ªå®ä¾‹ç‹¬ç«‹
    SHORT_TERM_WINDOW: int = field(default_factory=lambda: 30)  # çŸ­æœŸçª—å£
    MEDIUM_TERM_WINDOW: int = field(default_factory=lambda: 50)  # ä¸­æœŸçª—å£
    LONG_TERM_WINDOW: int = field(default_factory=lambda: 100)  # é•¿æœŸçª—å£
    ALL_HISTORY_WINDOW: Any = field(default_factory=lambda: None)  # å…¨éƒ¨å†å²

    # çƒ­å†·å·åˆ†æçª—å£
    HOT_COLD_WINDOW: int = field(default_factory=lambda: 30)  # é»˜è®¤ä½¿ç”¨çŸ­æœŸçª—å£

    def __post_init__(self):
        """
        åˆå§‹åŒ–åå¤„ç†ï¼šç¡®ä¿æ–°æ—§é…ç½®ä¸€è‡´

        æ³¨æ„ï¼šè¿™ä¸ª__post_init__ä¸PathConfigçš„__post_init__æ˜¯ç‹¬ç«‹çš„
        æ¯ä¸ªdataclasséƒ½æœ‰è‡ªå·±çš„__post_init__æ–¹æ³•
        """
        import logging
        logger = logging.getLogger(__name__)
        logger.debug("AnalysisConfig __post_init__ å¼€å§‹æ‰§è¡Œ")

        # å¦‚æœç”¨æˆ·é€šè¿‡æ–°é…ç½®è®¾ç½®äº†å€¼ï¼ŒåŒæ­¥åˆ°æ—§é…ç½®ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
        if self.SHORT_TERM_WINDOW != 30:  # ä¸æ˜¯é»˜è®¤å€¼
            self.TREND_ANALYSIS_WINDOW = self.SHORT_TERM_WINDOW
            logger.debug(f"åŒæ­¥é…ç½®: SHORT_TERM_WINDOW -> TREND_ANALYSIS_WINDOW = {self.SHORT_TERM_WINDOW}")

        if self.MEDIUM_TERM_WINDOW != 50:  # ä¸æ˜¯é»˜è®¤å€¼
            self.FREQUENCY_ANALYSIS_WINDOW = self.MEDIUM_TERM_WINDOW
            logger.debug(f"åŒæ­¥é…ç½®: MEDIUM_TERM_WINDOW -> FREQUENCY_ANALYSIS_WINDOW = {self.MEDIUM_TERM_WINDOW}")

        if self.LONG_TERM_WINDOW != 100:  # ä¸æ˜¯é»˜è®¤å€¼
            self.BASIC_STATS_WINDOW = self.LONG_TERM_WINDOW
            logger.debug(f"åŒæ­¥é…ç½®: LONG_TERM_WINDOW -> BASIC_STATS_WINDOW = {self.LONG_TERM_WINDOW}")

        # ç¡®ä¿çƒ­å†·å·çª—å£æœ‰å€¼
        if self.HOT_COLD_WINDOW == 30:  # è¿˜æ˜¯é»˜è®¤å€¼
            self.HOT_COLD_WINDOW = self.SHORT_TERM_WINDOW
            logger.debug(f"è®¾ç½® HOT_COLD_WINDOW = SHORT_TERM_WINDOW = {self.HOT_COLD_WINDOW}")

        logger.info(
            f"çª—å£é…ç½®åˆå§‹åŒ–å®Œæˆ: çŸ­æœŸ={self.SHORT_TERM_WINDOW}, ä¸­æœŸ={self.MEDIUM_TERM_WINDOW}, é•¿æœŸ={self.LONG_TERM_WINDOW}")

    @property
    def TREND_WINDOW_SIZES(self) -> List[Optional[int]]:
        """è·å–è¶‹åŠ¿åˆ†æçª—å£"""
        return self._TREND_WINDOW_SIZES

    @TREND_WINDOW_SIZES.setter
    def TREND_WINDOW_SIZES(self, value: List[Optional[int]]):
        """è®¾ç½®è¶‹åŠ¿åˆ†æçª—å£"""
        self._TREND_WINDOW_SIZES = value

    # æ¦‚ç‡åˆ†æé…ç½®
    PROBABILITY_ANALYSIS_ENABLED: bool = True
    REPEAT_PROBABILITY_WINDOW: int = 100
    COMBINATION_PROBABILITY_WINDOW: int = 100
    
    # çƒ­å·å†·å·åˆ†æ
    HOT_COLD_THRESHOLD: float = 0.3  # 30%ä½œä¸ºé˜ˆå€¼
    MIN_HOT_FREQUENCY: int = 2
    MAX_COLD_OMISSION: int = 20
    
    # è¶‹åŠ¿åˆ†æ
    TREND_SMOOTHING_WINDOW: int = 10
    DETECT_TREND_CHANGES: bool = True
    
    # å¯è§†åŒ–é…ç½®
    VISUALIZATION_ENABLED: bool = True
    SAVE_VISUALIZATIONS: bool = True
    VISUALIZATION_FORMAT: str = "png"  # png, pdf, svg
    DPI: int = 150
    FIGURE_SIZE: Tuple[int, int] = (12, 8)

@dataclass
class PredictionConfig:
    """é¢„æµ‹é…ç½®"""
    
    # æœºå™¨å­¦ä¹ é…ç½®
    ML_ENABLED: bool = True
    ML_MODEL_TYPE: str = "ensemble"  # random_forest, xgboost, lightgbm, ensemble
    TRAIN_TEST_SPLIT: float = 0.8
    CROSS_VALIDATION_FOLDS: int = 5
    MODEL_UPDATE_INTERVAL: int = 30  # æ¯30æœŸæ›´æ–°ä¸€æ¬¡æ¨¡å‹
    
    # ç‰¹å¾å·¥ç¨‹
    FEATURE_WINDOW: int = 50
    INCLUDE_STAT_FEATURES: bool = True
    INCLUDE_TEMPORAL_FEATURES: bool = True
    INCLUDE_PATTERN_FEATURES: bool = True
    
    # é¢„æµ‹ç­–ç•¥
    PREDICTION_STRATEGIES: List[str] = field(default_factory=lambda: [
        "frequency_based",
        "hot_cold",
        "statistical_trend",
        "pattern_recognition",
        "machine_learning"
    ])
    
    COMBINE_PREDICTIONS: bool = True
    MIN_CONFIDENCE_THRESHOLD: float = 0.6
    
    # å¤šç»„åˆé¢„æµ‹é…ç½®
    MULTIPLE_COMBINATIONS: Dict[str, bool] = field(default_factory=lambda: {
        '6_plus_1': True,   # åŸºç¡€ç»„åˆ
        '7_plus_1': True,   # æ‰©å±•ç»„åˆ
        '8_plus_1': True,   # é«˜çº§ç»„åˆ
        'multiple_sets': True  # å¤šç»„é¢„æµ‹
    })
    
    # é‡å·é¢„æµ‹é…ç½®
    REPEAT_PREDICTION_ENABLED: bool = True
    REPEAT_PREDICTION_METHOD: str = "ml_enhanced"  # simple, statistical, ml_enhanced
    MIN_REPEAT_CONFIDENCE: float = 0.3
    MAX_REPEAT_COUNT: int = 3

@dataclass
class ModelTrainingConfig:
    """æ¨¡å‹è®­ç»ƒé…ç½®"""
    
    # è®­ç»ƒé…ç½®
    TRAINING_ENABLED: bool = True
    TRAIN_ON_STARTUP: bool = False
    RETRAIN_INTERVAL: int = 30  # æ¯30æœŸé‡æ–°è®­ç»ƒ
    
    # æ•°æ®å‡†å¤‡
    TRAIN_WINDOW_SIZE: int = 200
    TRAIN_TEST_RATIO: float = 0.8
    RANDOM_STATE: int = 42
    
    # æ¨¡å‹å‚æ•°
    XGBOOST_PARAMS: Dict[str, Any] = field(default_factory=lambda: {
        'n_estimators': 100,
        'max_depth': 6,
        'learning_rate': 0.1
    })
    
    LIGHTGBM_PARAMS: Dict[str, Any] = field(default_factory=lambda: {
        'n_estimators': 100,
        'max_depth': 6,
        'learning_rate': 0.1
    })

@dataclass
class ExportConfig:
    """å¯¼å‡ºé…ç½®"""
    
    # å¯¼å‡ºå¯ç”¨
    EXPORT_ENABLED: bool = True
    
    # æ ¼å¼é…ç½®
    DEFAULT_EXPORT_FORMAT: str = "csv"  # csv, json, excel
    
    # æ–‡ä»¶ç®¡ç†
    AUTO_CLEANUP: bool = True
    MAX_EXPORT_FILES: int = 50

@dataclass
class UIConfig:
    """ç”¨æˆ·ç•Œé¢é…ç½®"""
    
    # ç•Œé¢æ¨¡å¼é…ç½®
    INTERFACE_MODE: str = "colorful"  # colorful, simple, enhanced
    INTERACTIVE_MODE: bool = True
    SHOW_PROGRESS_BARS: bool = True
    
    # æ˜¾ç¤ºé…ç½®
    COLOR_OUTPUT: bool = True
    EMOJI_ENABLED: bool = True
    DISPLAY_BANNER: bool = True
    
    # èœå•é…ç½®
    MAIN_MENU_OPTIONS: List[Dict[str, Any]] = field(default_factory=lambda: [
        {"id": "sync", "name": "ğŸ“¡ æ•°æ®åŒæ­¥", "description": "åŒæ­¥æœ€æ–°å¼€å¥–æ•°æ®", "color": "cyan"},
        {"id": "analyze", "name": "ğŸ“Š æ•°æ®åˆ†æ", "description": "ç»Ÿè®¡åˆ†æå†å²æ•°æ®", "color": "green"},
        {"id": "predict", "name": "ğŸ¯ åŸºç¡€é¢„æµ‹", "description": "é¢„æµ‹ä¸‹ä¸€æœŸå·ç ï¼ˆ6+1ï¼‰", "color": "yellow"},
        {"id": "enhanced_predict", "name": "ğŸš€ å¢å¼ºé¢„æµ‹", "description": "å¢å¼ºé¢„æµ‹ï¼ˆ7+1, 8+1ç»„åˆï¼‰", "color": "magenta"},
        {"id": "visualize", "name": "ğŸ“ˆ æ•°æ®å¯è§†åŒ–", "description": "ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨", "color": "blue"},
        {"id": "workflow", "name": "âš™ï¸  å®Œæ•´è¿è¡Œ", "description": "æ‰§è¡Œå®Œæ•´åˆ†ææµç¨‹", "color": "white"},
        {"id": "system", "name": "ğŸ”§ ç³»ç»Ÿä¿¡æ¯", "description": "æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€", "color": "gray"},
        {"id": "exit", "name": "âŒ é€€å‡ºç³»ç»Ÿ", "description": "é€€å‡ºç¨‹åº", "color": "red"}
    ])
    
    # è¾“å‡ºæ ¼å¼
    DATE_FORMAT: str = "%Y-%m-%d"
    TIME_FORMAT: str = "%H:%M:%S"
    NUMBER_FORMAT: str = "02d"  # å·ç æ˜¾ç¤ºæ ¼å¼

@dataclass
class SystemConfig:
    """ç³»ç»Ÿé…ç½®"""
    
    # ç³»ç»Ÿè®¾ç½®
    APP_NAME: str = "åŒè‰²çƒæ™ºèƒ½åˆ†æç³»ç»Ÿ"
    VERSION: str = "3.0.0"
    DEBUG: bool = False
    TEST_MODE: bool = False
    ENVIRONMENT: str = "production"  # production, development, testing
    
    # æ—¥å¿—é…ç½®
    LOG_LEVEL: str = "INFO"
    LOG_FORMAT: str = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    LOG_MAX_SIZE: int = 10 * 1024 * 1024  # 10MB
    LOG_BACKUP_COUNT: int = 5
    LOG_TO_FILE: bool = True
    LOG_TO_CONSOLE: bool = True
    
    # æ€§èƒ½é…ç½®
    CACHE_ENABLED: bool = True
    CACHE_TTL: int = 3600
    MAX_WORKERS: int = 4
    
    # ç³»ç»Ÿæ¨¡å—é…ç½®
    MODULES_ENABLED: Dict[str, bool] = field(default_factory=lambda: {
        'crawler': True,
        'database': True,
        'processor': True,
        'advanced_processor': True,
        'predictor': True,
        'statistics': True,
        'visualization': True,
        'display': True,
        'interactive': True,
        'workflow': True,
        'model_training': True,
        'export': True
    })
    
    # ç³»ç»Ÿå®‰å…¨
    DATA_VALIDATION: bool = True
    BACKUP_ON_ERROR: bool = True

@dataclass
class WorkflowConfig:
    """å·¥ä½œæµç¨‹é…ç½®"""
    
    # å·¥ä½œæµç¨‹å¯ç”¨
    ENABLE_WORKFLOWS: bool = True
    
    # æ•°æ®å¤„ç†æµç¨‹
    DATA_PIPELINE_STEPS: List[str] = field(default_factory=lambda: [
        "data_validation",
        "data_cleaning",
        "feature_extraction",
        "feature_engineering"
    ])
    
    # åˆ†ææµç¨‹
    ANALYSIS_WORKFLOW_STEPS: List[str] = field(default_factory=lambda: [
        "basic_statistics",
        "frequency_analysis",
        "trend_analysis",
        "hot_cold_analysis",
        "pattern_recognition"
    ])
    
    # é¢„æµ‹æµç¨‹
    PREDICTION_WORKFLOW_STEPS: List[str] = field(default_factory=lambda: [
        "data_preparation",
        "feature_selection",
        "model_prediction",
        "result_combination",
        "confidence_calculation"
    ])

class ConfigManager:
    """é…ç½®ç®¡ç†å™¨ (å•ä¾‹æ¨¡å¼)"""

    _instance = None
    _initialized = False

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(ConfigManager, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if not self._initialized:
            self._initialize()
            self._initialized = True

    def _initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰é…ç½®"""
        # ç¬¬ä¸€æ­¥ï¼šå…ˆè®¾ç½®åŸºç¡€æ—¥å¿—ï¼Œé¿å…åç»­é…ç½®å¯¹è±¡åˆå§‹åŒ–æ—¶å‡ºé”™
        self._setup_basic_logging()

        # ç¬¬äºŒæ­¥ï¼šåˆ›å»ºé…ç½®å¯¹è±¡
        self.paths = PathConfig()
        self.database = DatabaseConfig()
        self.crawler = CrawlerConfig()
        self.processor = ProcessorConfig()
        self.analysis = AnalysisConfig()
        self.prediction = PredictionConfig()
        self.model_training = ModelTrainingConfig()
        self.export = ExportConfig()
        self.ui = UIConfig()
        self.system = SystemConfig()
        self.workflow = WorkflowConfig()

        # ç¬¬ä¸‰æ­¥ï¼šåº”ç”¨å®Œæ•´çš„æ—¥å¿—é…ç½®
        self._setup_logging()

        logging.info(f"é…ç½®åˆå§‹åŒ–å®Œæˆï¼Œç³»ç»Ÿç‰ˆæœ¬: {self.system.VERSION}")

    def _setup_basic_logging(self):
        """è®¾ç½®åŸºç¡€æ—¥å¿—ï¼ˆä¸ä¾èµ–ä»»ä½•é…ç½®å¯¹è±¡ï¼‰"""
        # æ¸…ç©ºç°æœ‰å¤„ç†å™¨
        for handler in logging.root.handlers[:]:
            logging.root.removeHandler(handler)

        # æ·»åŠ ç®€å•çš„æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(levelname)s - %(message)s')
        console_handler.setFormatter(formatter)
        logging.root.addHandler(console_handler)
        logging.root.setLevel(logging.INFO)

    def _setup_logging(self):
        """è®¾ç½®å®Œæ•´çš„æ—¥å¿—é…ç½®ï¼ˆä¾èµ–é…ç½®å¯¹è±¡å·²åˆ›å»ºï¼‰"""
        # å¦‚æœç³»ç»Ÿé…ç½®ä¸­æŒ‡å®šäº†æ—¥å¿—çº§åˆ«ï¼Œåˆ™ä½¿ç”¨è¯¥çº§åˆ«
        log_level = getattr(logging, self.system.LOG_LEVEL)

        # ç§»é™¤æ‰€æœ‰ç°æœ‰å¤„ç†å™¨
        for handler in logging.root.handlers[:]:
            logging.root.removeHandler(handler)

        # åˆ›å»ºæ ¼å¼åŒ–å™¨
        formatter = logging.Formatter(self.system.LOG_FORMAT)

        # æ–‡ä»¶å¤„ç†å™¨
        if self.system.LOG_TO_FILE:
            try:
                file_handler = logging.FileHandler(self.paths.MAIN_LOG, encoding='utf-8')
                file_handler.setLevel(log_level)
                file_handler.setFormatter(formatter)
                logging.root.addHandler(file_handler)
            except Exception as e:
                logging.warning(f"æ— æ³•åˆ›å»ºæ—¥å¿—æ–‡ä»¶å¤„ç†å™¨: {e}")

        # æ§åˆ¶å°å¤„ç†å™¨
        if self.system.LOG_TO_CONSOLE:
            console_handler = logging.StreamHandler()
            console_level = logging.DEBUG if self.system.DEBUG else log_level
            console_handler.setLevel(console_level)
            console_handler.setFormatter(formatter)
            logging.root.addHandler(console_handler)

        # è®¾ç½®æ ¹æ—¥å¿—çº§åˆ«
        logging.root.setLevel(log_level)

    def get_database_path(self) -> str:
        """è·å–æ•°æ®åº“è·¯å¾„"""
        return self.paths.DATABASE_PATH

    def display_config_summary(self):
        """æ˜¾ç¤ºé…ç½®æ‘˜è¦"""
        print("\n" + "=" * 70)
        print(f"åŒè‰²çƒåˆ†æç³»ç»Ÿ - é…ç½®æ‘˜è¦ (ç‰ˆæœ¬ {self.system.VERSION})")
        print("=" * 70)

        print(f"\nğŸ“‚ è·¯å¾„é…ç½® (å®é™…ä½ç½®):")
        print(f"  é¡¹ç›®æ ¹ç›®å½•: {self.paths.BASE_DIR}")
        print(f"  æ•°æ®åº“è·¯å¾„: {self.paths.DATABASE_PATH} âœ… (å®é™…ä½ç½®)")
        print(f"  æŠ¥å‘Šç›®å½•: {self.paths.REPORTS_DIR} âœ… (å®é™…ä½ç½®)")
        print(f"  æ—¥å¿—ç›®å½•: {self.paths.LOGS_DIR}")

        print(f"\nğŸ“Š åˆ†æé…ç½® (ç»Ÿä¸€çª—å£å‘½å):")
        print(f"  çŸ­æœŸçª—å£: {self.analysis.SHORT_TERM_WINDOW} æœŸ")
        print(f"  ä¸­æœŸçª—å£: {self.analysis.MEDIUM_TERM_WINDOW} æœŸ")
        print(f"  é•¿æœŸçª—å£: {self.analysis.LONG_TERM_WINDOW} æœŸ")
        print(f"  çƒ­å†·å·çª—å£: {self.analysis.HOT_COLD_WINDOW} æœŸ")

        print(f"\nğŸ¤– é¢„æµ‹é…ç½®:")
        print(f"  æœºå™¨å­¦ä¹ : {'âœ… å¯ç”¨' if self.prediction.ML_ENABLED else 'âŒ ç¦ç”¨'}")
        print(f"  æ”¯æŒç»„åˆ: {', '.join([k for k, v in self.prediction.MULTIPLE_COMBINATIONS.items() if v])}")

        print(f"\nğŸš€ ç³»ç»Ÿé…ç½®:")
        print(f"  è¿è¡Œç¯å¢ƒ: {self.system.ENVIRONMENT}")
        print(f"  æ—¥å¿—çº§åˆ«: {self.system.LOG_LEVEL}")

        print(f"\nğŸ“ˆ æ¨¡å—çŠ¶æ€:")
        enabled_modules = [k for k, v in self.system.MODULES_ENABLED.items() if v]
        print(f"  å¯ç”¨æ¨¡å—: {len(enabled_modules)}/{len(self.system.MODULES_ENABLED)}")

        print("\n" + "=" * 70)
        print("ğŸ’¡ æç¤º: ç³»ç»Ÿå·²ä½¿ç”¨ç»Ÿä¸€çª—å£é…ç½®ï¼Œæ–°æ—§é…ç½®åç§°è‡ªåŠ¨åŒæ­¥")

# å…¨å±€é…ç½®å®ä¾‹
config = ConfigManager()

if __name__ == "__main__":
    """ç›´æ¥è¿è¡Œconfig.pyæ—¶æ˜¾ç¤ºé…ç½®ä¿¡æ¯"""
    config.display_config_summary()
    
    # éªŒè¯é…ç½®
    if config.paths.DATABASE_PATH and os.path.exists(config.paths.DATABASE_PATH):
        print(f"\nâœ… æ•°æ®åº“æ–‡ä»¶å­˜åœ¨: {config.paths.DATABASE_PATH}")
    else:
        print(f"\nâš ï¸  æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {config.paths.DATABASE_PATH}")
        print("   é¦–æ¬¡è¿è¡Œå‰è¯·å…ˆæ‰§è¡Œæ•°æ®åŒæ­¥")
    
    print(f"\nğŸ¯ ç³»ç»Ÿåç§°: {config.system.APP_NAME}")
    print(f"ğŸ“… åˆå§‹åŒ–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")