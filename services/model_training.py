# services/model_training.py - å®Œæ•´ä¿®å¤ç‰ˆæœ¬
"""
æ¨¡å‹è®­ç»ƒæœåŠ¡ - ä¿®å¤ç‰ˆæœ¬
ä¿®å¤XGBoostæ ‡ç­¾ç¼–ç ã€LightGBMç‰ˆæœ¬å…¼å®¹æ€§ã€ç»Ÿè®¡æ¨¡å‹ç®—æ³•
"""
import logging
import pickle
import os
from typing import Dict, Any, List, Tuple
import numpy as np
import pandas as pd
from datetime import datetime
from dataclasses import dataclass
from collections import Counter

from data.database import DoubleBallDatabase
from utils.db_manager import DatabaseManager

logger = logging.getLogger('model_training')

@dataclass
class TrainingConfig:
    """è®­ç»ƒé…ç½®"""
    train_ratio: float = 0.8
    validation_ratio: float = 0.1
    test_ratio: float = 0.1
    random_state: int = 42
    n_estimators: int = 100
    max_depth: int = 6
    learning_rate: float = 0.1

class ModelTrainingService:
    """æ¨¡å‹è®­ç»ƒæœåŠ¡ - ä¿®å¤ç‰ˆæœ¬"""
    
    def __init__(self, db_path: str = None):
        self.db_manager = DatabaseManager()
        
        if db_path is None:
            from config import config
            db_path = config.paths.DATABASE_PATH
        
        self.db = self.db_manager.get_db(db_path)
        self.config = TrainingConfig()
        
        # æ¨¡å‹å­˜å‚¨è·¯å¾„
        self.models_dir = "models"
        os.makedirs(self.models_dir, exist_ok=True)
        
        logger.info("æ¨¡å‹è®­ç»ƒæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    def prepare_training_data(self, window_size: int = 100) -> Tuple[np.ndarray, np.ndarray]:
        """
        å‡†å¤‡è®­ç»ƒæ•°æ®
        
        Args:
            window_size: ä½¿ç”¨çš„å†å²æœŸæ•°
            
        Returns:
            X: ç‰¹å¾çŸ©é˜µ
            y: æ ‡ç­¾
        """
        try:
            # è·å–æ•°æ®
            records = self.db.get_recent_records(window_size)
            if len(records) < 10:
                logger.warning(f"æ•°æ®ä¸è¶³ï¼Œåªæœ‰ {len(records)} æ¡è®°å½•")
                return None, None
            
            # è½¬æ¢ä¸ºç‰¹å¾çŸ©é˜µ
            features = []
            labels_red = []
            labels_blue = []
            
            for i in range(len(records) - 1):
                current = records[i]
                next_record = records[i + 1]
                
                # ç‰¹å¾ï¼šå½“å‰æœŸçš„çº¢çƒå’Œè“çƒ
                red_features = [
                    current.red1, current.red2, current.red3,
                    current.red4, current.red5, current.red6
                ]
                blue_feature = [current.blue]
                
                # æ·»åŠ ç»Ÿè®¡ç‰¹å¾
                red_sum = sum(red_features)
                red_avg = red_sum / 6
                red_std = np.std(red_features)
                odd_count = sum(1 for x in red_features if x % 2 == 1)
                
                # ç»„åˆç‰¹å¾
                feature_vector = red_features + blue_feature + [
                    red_sum, red_avg, red_std, odd_count,
                    i % 7,  # æ˜ŸæœŸå‡ çš„ç®€å•è¡¨ç¤º
                    len(records) - i  # æ—¶é—´è¡°å‡
                ]
                
                features.append(feature_vector)
                
                # æ ‡ç­¾ï¼šä¸‹æœŸçš„çº¢çƒå’Œè“çƒ
                labels_red.append([
                    next_record.red1, next_record.red2, next_record.red3,
                    next_record.red4, next_record.red5, next_record.red6
                ])
                labels_blue.append([next_record.blue])
            
            X = np.array(features, dtype=np.float32)
            y_red = np.array(labels_red, dtype=np.int32)
            y_blue = np.array(labels_blue, dtype=np.int32)
            
            logger.info(f"æ•°æ®å‡†å¤‡å®Œæˆ: X.shape={X.shape}, y_red.shape={y_red.shape}")
            return X, (y_red, y_blue)
            
        except Exception as e:
            logger.error(f"å‡†å¤‡è®­ç»ƒæ•°æ®å¤±è´¥: {e}", exc_info=True)
            return None, None
    
    def train_xgboost_model(self, X: np.ndarray, y_red: np.ndarray, y_blue: np.ndarray) -> Dict[str, Any]:
        """è®­ç»ƒXGBoostæ¨¡å‹ - ä½¿ç”¨DMatrix APIé¿å…æ ‡ç­¾æ£€æŸ¥é—®é¢˜"""
        try:
            import xgboost as xgb
            from sklearn.model_selection import train_test_split
            from sklearn.metrics import accuracy_score
            
            logger.info(f"å¼€å§‹è®­ç»ƒXGBoostæ¨¡å‹ï¼Œæ•°æ®å½¢çŠ¶: X={X.shape}, y_red={y_red.shape}, y_blue={y_blue.shape}")
            
            # ç¼–ç æ ‡ç­¾
            y_red_encoded = y_red - 1  # 1-33 -> 0-32
            y_blue_encoded = y_blue.ravel() - 1  # 1-16 -> 0-15
            
            # ä½¿ç”¨åˆ†å±‚æŠ½æ ·ç¡®ä¿è“çƒåˆ†å¸ƒå‡åŒ€
            X_train, X_test, y_red_train_encoded, y_red_test_encoded, y_blue_train_encoded, y_blue_test_encoded = train_test_split(
                X, y_red_encoded, y_blue_encoded, 
                test_size=0.2, 
                random_state=self.config.random_state,
                stratify=y_blue_encoded  # ğŸ”§ å…³é”®ï¼šæŒ‰è“çƒåˆ†å±‚æŠ½æ ·
            )
            
            logger.info(f"è®­ç»ƒé›†: {X_train.shape[0]}æ¡, æµ‹è¯•é›†: {X_test.shape[0]}æ¡")
            logger.info(f"è®­ç»ƒé›†è“çƒæ ‡ç­¾: {sorted(np.unique(y_blue_train_encoded))}")
            logger.info(f"æµ‹è¯•é›†è“çƒæ ‡ç­¾: {sorted(np.unique(y_blue_test_encoded))}")
            
            # è§£ç ç”¨äºè¯„ä¼°
            y_red_test = y_red_test_encoded + 1
            y_blue_test = y_blue_test_encoded + 1
            
            # è®­ç»ƒçº¢çƒæ¨¡å‹
            red_models = []
            red_accuracies = []
            
            for i in range(6):
                y_train_single_encoded = y_red_train_encoded[:, i]
                y_test_single_encoded = y_red_test_encoded[:, i]
                y_test_single = y_red_test[:, i]
                
                # ğŸ”§ ä½¿ç”¨DMatrixç›´æ¥è®­ç»ƒï¼Œé¿å…sklearn wrapperçš„ç±»åˆ«æ£€æŸ¥
                dtrain = xgb.DMatrix(X_train, label=y_train_single_encoded)
                dtest = xgb.DMatrix(X_test, label=y_test_single_encoded)
                
                params = {
                    'objective': 'multi:softmax',
                    'num_class': 33,
                    'max_depth': self.config.max_depth,
                    'eta': self.config.learning_rate,
                    'seed': self.config.random_state,
                    'verbosity': 0,
                    'eval_metric': 'merror'
                }
                
                # è®­ç»ƒæ¨¡å‹
                model = xgb.train(
                    params=params,
                    dtrain=dtrain,
                    num_boost_round=self.config.n_estimators,
                    evals=[(dtrain, 'train'), (dtest, 'eval')],
                    early_stopping_rounds=10,
                    verbose_eval=False
                )
                
                # é¢„æµ‹
                y_pred_encoded = model.predict(dtest).astype(int)
                y_pred = y_pred_encoded + 1
                
                accuracy = accuracy_score(y_test_single, y_pred)
                
                red_models.append(model)
                red_accuracies.append(accuracy)
                
                logger.info(f"çº¢çƒä½ç½® {i+1} æ¨¡å‹å‡†ç¡®ç‡: {accuracy:.4f}")
            
            # è®­ç»ƒè“çƒæ¨¡å‹
            dtrain_blue = xgb.DMatrix(X_train, label=y_blue_train_encoded)
            dtest_blue = xgb.DMatrix(X_test, label=y_blue_test_encoded)
            
            params_blue = {
                'objective': 'multi:softmax',
                'num_class': 16,
                'max_depth': self.config.max_depth,
                'eta': self.config.learning_rate,
                'seed': self.config.random_state,
                'verbosity': 0,
                'eval_metric': 'merror'
            }
            
            blue_model = xgb.train(
                params=params_blue,
                dtrain=dtrain_blue,
                num_boost_round=self.config.n_estimators,
                evals=[(dtrain_blue, 'train'), (dtest_blue, 'eval')],
                early_stopping_rounds=10,
                verbose_eval=False
            )
            
            y_blue_pred_encoded = blue_model.predict(dtest_blue).astype(int)
            y_blue_pred = y_blue_pred_encoded + 1
            
            blue_accuracy = accuracy_score(y_blue_test, y_blue_pred)
            logger.info(f"è“çƒæ¨¡å‹å‡†ç¡®ç‡: {blue_accuracy:.4f}")
            
            # ä¿å­˜æ¨¡å‹
            model_info = {
                'red_models': red_models,
                'blue_model': blue_model,
                'red_accuracies': red_accuracies,
                'blue_accuracy': blue_accuracy,
                'train_size': X_train.shape[0],
                'test_size': X_test.shape[0],
                'feature_count': X.shape[1],
                'train_time': datetime.now().isoformat(),
                'model_type': 'xgboost_dmatrix'
            }
            
            model_path = os.path.join(self.models_dir, "xgboost_model.pkl")
            with open(model_path, 'wb') as f:
                pickle.dump(model_info, f)
            
            logger.info(f"XGBoostæ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
            return model_info
            
        except ImportError:
            logger.error("XGBoostæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install xgboost")
            return {'error': 'XGBoostæœªå®‰è£…'}
        except Exception as e:
            logger.error(f"è®­ç»ƒXGBoostæ¨¡å‹å¤±è´¥: {e}", exc_info=True)
            return {'error': str(e)}

    def train_lightgbm_model(self, X: np.ndarray, y_red: np.ndarray, y_blue: np.ndarray) -> Dict[str, Any]:
        """è®­ç»ƒLightGBMæ¨¡å‹ - ä½¿ç”¨åŸç”ŸAPIé¿å…sklearnå…¼å®¹æ€§é—®é¢˜"""
        try:
            import lightgbm as lgb
            from sklearn.model_selection import train_test_split
            from sklearn.metrics import accuracy_score
            import warnings
            warnings.filterwarnings('ignore')

            logger.info(f"å¼€å§‹è®­ç»ƒLightGBMæ¨¡å‹ï¼Œæ•°æ®å½¢çŠ¶: X={X.shape}, y_red={y_red.shape}, y_blue={y_blue.shape}")

            # ç¼–ç æ ‡ç­¾
            y_red_encoded = y_red - 1
            y_blue_encoded = y_blue.ravel() - 1

            # ä½¿ç”¨åˆ†å±‚æŠ½æ ·ç¡®ä¿è“çƒåˆ†å¸ƒå‡åŒ€
            X_train, X_test, y_red_train_encoded, y_red_test_encoded, y_blue_train_encoded, y_blue_test_encoded = train_test_split(
                X, y_red_encoded, y_blue_encoded,
                test_size=0.2,
                random_state=self.config.random_state,
                stratify=y_blue_encoded
            )

            # è§£ç ç”¨äºè¯„ä¼°
            y_red_test = y_red_test_encoded + 1
            y_blue_test = y_blue_test_encoded + 1

            # ğŸ”§ ä½¿ç”¨LightGBMåŸç”ŸDataset API
            red_models = []
            red_accuracies = []

            # åˆ›å»ºæ•°æ®é›†
            train_data = lgb.Dataset(X_train)
            test_data = lgb.Dataset(X_test, reference=train_data)

            for i in range(6):
                y_train_single_encoded = y_red_train_encoded[:, i]
                y_test_single = y_red_test[:, i]

                # è®¾ç½®æ ‡ç­¾
                train_data.set_label(y_train_single_encoded)

                # å‚æ•°é…ç½®
                params = {
                    'objective': 'multiclass',
                    'num_class': 33,
                    'num_leaves': 31,
                    'learning_rate': self.config.learning_rate,
                    'feature_fraction': 0.8,
                    'bagging_fraction': 0.8,
                    'bagging_freq': 5,
                    'verbose': -1,
                    'seed': self.config.random_state
                }

                # è®­ç»ƒæ¨¡å‹
                model = lgb.train(
                    params,
                    train_data,
                    num_boost_round=self.config.n_estimators,
                    valid_sets=[test_data],
                    callbacks=[lgb.log_evaluation(0)]  # ä¸æ˜¾ç¤ºæ—¥å¿—
                )

                # é¢„æµ‹
                y_pred_encoded = model.predict(X_test, num_iteration=model.best_iteration)
                y_pred = np.argmax(y_pred_encoded, axis=1) + 1

                accuracy = accuracy_score(y_test_single, y_pred)

                red_models.append(model)
                red_accuracies.append(accuracy)

                logger.info(f"LightGBMçº¢çƒä½ç½® {i + 1} æ¨¡å‹å‡†ç¡®ç‡: {accuracy:.4f}")

            # è®­ç»ƒè“çƒæ¨¡å‹
            train_data_blue = lgb.Dataset(X_train, label=y_blue_train_encoded)
            test_data_blue = lgb.Dataset(X_test, label=y_blue_test_encoded, reference=train_data_blue)

            params_blue = {
                'objective': 'multiclass',
                'num_class': 16,
                'num_leaves': 31,
                'learning_rate': self.config.learning_rate,
                'feature_fraction': 0.8,
                'bagging_fraction': 0.8,
                'bagging_freq': 5,
                'verbose': -1,
                'seed': self.config.random_state
            }

            blue_model = lgb.train(
                params_blue,
                train_data_blue,
                num_boost_round=self.config.n_estimators,
                valid_sets=[test_data_blue],
                callbacks=[lgb.log_evaluation(0)]
            )

            y_blue_pred_encoded = blue_model.predict(X_test, num_iteration=blue_model.best_iteration)
            y_blue_pred = np.argmax(y_blue_pred_encoded, axis=1) + 1

            blue_accuracy = accuracy_score(y_blue_test, y_blue_pred)
            logger.info(f"LightGBMè“çƒæ¨¡å‹å‡†ç¡®ç‡: {blue_accuracy:.4f}")

            # ä¿å­˜æ¨¡å‹
            model_info = {
                'red_models': red_models,
                'blue_model': blue_model,
                'red_accuracies': red_accuracies,
                'blue_accuracy': blue_accuracy,
                'model_type': 'lightgbm_native',
                'train_time': datetime.now().isoformat(),
                'label_encoding': '1-based_to_0-based'
            }

            model_path = os.path.join(self.models_dir, "lightgbm_model.pkl")
            with open(model_path, 'wb') as f:
                pickle.dump(model_info, f)

            logger.info(f"LightGBMæ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
            return model_info

        except ImportError:
            logger.error("LightGBMæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install lightgbm")
            return {'error': 'LightGBMæœªå®‰è£…'}
        except Exception as e:
            logger.error(f"è®­ç»ƒLightGBMæ¨¡å‹å¤±è´¥: {e}", exc_info=True)
            return {'error': str(e)}
    
    def train_statistical_model(self) -> Dict[str, Any]:
        """è®­ç»ƒç»Ÿè®¡æ¨¡å‹ï¼ˆåŸºäºé¢‘ç‡åˆ†æï¼‰- ä¿®å¤çƒ­å†·å·ç®—æ³•"""
        try:
            # è·å–å†å²æ•°æ®
            records = self.db.get_all_records()
            if len(records) < 50:
                logger.warning("æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®­ç»ƒç»Ÿè®¡æ¨¡å‹")
                return {'error': 'æ•°æ®ä¸è¶³'}
            
            # ç»Ÿè®¡çº¢çƒé¢‘ç‡ - ğŸ”§ ä½¿ç”¨å·²å¯¼å…¥çš„Counter
            red_counts = Counter()
            blue_counts = Counter()
            
            for record in records:
                reds = [record.red1, record.red2, record.red3,
                       record.red4, record.red5, record.red6]
                
                for ball in reds:
                    red_counts[ball] = red_counts.get(ball, 0) + 1
                
                blue_counts[record.blue] = blue_counts.get(record.blue, 0) + 1
            
            total_games = len(records)
            
            # è®¡ç®—ç†è®ºå¹³å‡å‡ºç°æ¬¡æ•°
            theoretical_red_freq = total_games * 6 / 33
            
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨å®é™…ç»Ÿè®¡æ’å
            sorted_reds = red_counts.most_common()
            
            # å–å‰33%ä½œä¸ºçƒ­å·ï¼ˆå¤§çº¦11ä¸ªå·ç ï¼‰
            hot_count = max(1, int(len(sorted_reds) * 0.33))
            hot_reds = [ball for ball, _ in sorted_reds[:hot_count]]
            
            # å–å33%ä½œä¸ºå†·å·
            cold_count = max(1, int(len(sorted_reds) * 0.33))
            cold_reds = [ball for ball, _ in sorted_reds[-cold_count:]]
            
            # æ¸©å·æ˜¯ä¸­é—´çš„éƒ¨åˆ†
            warm_reds = []
            if len(sorted_reds) > (hot_count + cold_count):
                warm_reds = [ball for ball, _ in sorted_reds[hot_count:-cold_count]]
            
            # è®¡ç®—æ¦‚ç‡
            red_probabilities = {
                ball: count / (total_games * 6)
                for ball, count in red_counts.items()
            }
            
            blue_probabilities = {
                ball: count / total_games
                for ball, count in blue_counts.items()
            }
            
            # è·å–æœ€çƒ­é—¨çš„10ä¸ªçº¢çƒå’Œæœ€å†·é—¨çš„10ä¸ªçº¢çƒ
            hot_reds_top10 = [ball for ball, _ in sorted_reds[:10]]
            cold_reds_top10 = [ball for ball, _ in sorted_reds[-10:]]
            
            model_info = {
                'red_probabilities': red_probabilities,
                'blue_probabilities': blue_probabilities,
                'hot_reds': hot_reds,
                'warm_reds': warm_reds,
                'cold_reds': cold_reds,
                'hot_reds_top10': hot_reds_top10,
                'cold_reds_top10': cold_reds_top10,
                'total_games': total_games,
                'model_type': 'statistical',
                'train_time': datetime.now().isoformat(),
                'classification_method': 'ranking_top_bottom_33_percent',
                'red_counts_dict': dict(red_counts),
                'blue_counts_dict': dict(blue_counts)
            }
            
            # ä¿å­˜æ¨¡å‹
            model_path = os.path.join(self.models_dir, "statistical_model.pkl")
            with open(model_path, 'wb') as f:
                pickle.dump(model_info, f)
            
            logger.info(f"ç»Ÿè®¡æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
            logger.info(f"çƒ­å·: {len(hot_reds)}ä¸ª, æ¸©å·: {len(warm_reds)}ä¸ª, å†·å·: {len(cold_reds)}ä¸ª")
            logger.info(f"çƒ­é—¨çº¢çƒTOP10: {hot_reds_top10}")
            logger.info(f"å†·é—¨çº¢çƒTOP10: {cold_reds_top10}")
            return model_info
            
        except Exception as e:
            logger.error(f"è®­ç»ƒç»Ÿè®¡æ¨¡å‹å¤±è´¥: {e}", exc_info=True)
            return {'error': str(e)}
    
    def train_all_models(self, window_size: int = 200) -> Dict[str, Any]:
        """è®­ç»ƒæ‰€æœ‰æ¨¡å‹"""
        try:
            # å‡†å¤‡æ•°æ®
            X, (y_red, y_blue) = self.prepare_training_data(window_size)
            if X is None:
                return {'error': 'æ— æ³•å‡†å¤‡è®­ç»ƒæ•°æ®'}
            
            results = {}
            
            # è®­ç»ƒXGBoostæ¨¡å‹
            logger.info("å¼€å§‹è®­ç»ƒXGBoostæ¨¡å‹...")
            xgb_result = self.train_xgboost_model(X, y_red, y_blue)
            results['xgboost'] = xgb_result
            
            # è®­ç»ƒLightGBMæ¨¡å‹
            logger.info("å¼€å§‹è®­ç»ƒLightGBMæ¨¡å‹...")
            lgb_result = self.train_lightgbm_model(X, y_red, y_blue)
            results['lightgbm'] = lgb_result
            
            # è®­ç»ƒç»Ÿè®¡æ¨¡å‹
            logger.info("å¼€å§‹è®­ç»ƒç»Ÿè®¡æ¨¡å‹...")
            stats_result = self.train_statistical_model()
            results['statistical'] = stats_result
            
            # ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š
            report = self.generate_training_report(results)
            
            logger.info("æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆ")
            return {
                'success': True,
                'results': results,
                'report': report,
                'total_time': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"è®­ç»ƒæ‰€æœ‰æ¨¡å‹å¤±è´¥: {e}", exc_info=True)
            return {'error': str(e)}
    
    def generate_training_report(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š"""
        report_lines = []
        report_lines.append("=" * 60)
        report_lines.append("æ¨¡å‹è®­ç»ƒæŠ¥å‘Š")
        report_lines.append("=" * 60)
        report_lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        for model_name, result in results.items():
            report_lines.append(f"\nğŸ“Š {model_name.upper()} æ¨¡å‹:")
            
            if 'error' in result:
                report_lines.append(f"  çŠ¶æ€: å¤±è´¥ - {result['error']}")
                continue
            
            report_lines.append(f"  çŠ¶æ€: æˆåŠŸ")
            
            if model_name in ['xgboost', 'lightgbm']:
                red_accuracies = result.get('red_accuracies', [])
                blue_accuracy = result.get('blue_accuracy', 0)
                
                if red_accuracies:
                    avg_red_accuracy = sum(red_accuracies) / len(red_accuracies)
                    report_lines.append(f"  çº¢çƒå¹³å‡å‡†ç¡®ç‡: {avg_red_accuracy:.4f}")
                    report_lines.append(f"  è“çƒå‡†ç¡®ç‡: {blue_accuracy:.4f}")
                    
                    for i, acc in enumerate(red_accuracies):
                        report_lines.append(f"    ä½ç½®{i+1}: {acc:.4f}")
            
            elif model_name == 'statistical':
                hot_reds = result.get('hot_reds', [])
                warm_reds = result.get('warm_reds', [])
                cold_reds = result.get('cold_reds', [])
                total_games = result.get('total_games', 0)
                
                report_lines.append(f"  åŸºäºæ•°æ®: {total_games} æœŸ")
                report_lines.append(f"  çƒ­å·æ•°é‡: {len(hot_reds)} ä¸ª")
                report_lines.append(f"  æ¸©å·æ•°é‡: {len(warm_reds)} ä¸ª")
                report_lines.append(f"  å†·å·æ•°é‡: {len(cold_reds)} ä¸ª")
                
                hot_top10 = result.get('hot_reds_top10', [])
                cold_top10 = result.get('cold_reds_top10', [])
                if hot_top10:
                    report_lines.append(f"  çƒ­é—¨çº¢çƒTOP10: {sorted(hot_top10)}")
                if cold_top10:
                    report_lines.append(f"  å†·é—¨çº¢çƒTOP10: {sorted(cold_top10)}")
        
        report_lines.append(f"\nğŸ’¡ è¯´æ˜:")
        report_lines.append("  â€¢ å‡†ç¡®ç‡åŸºäºæµ‹è¯•é›†è®¡ç®—")
        report_lines.append("  â€¢ ç»Ÿè®¡æ¨¡å‹åŸºäºé¢‘ç‡åˆ†æ")
        report_lines.append("  â€¢ æœºå™¨å­¦ä¹ æ¨¡å‹åŸºäºå†å²æ•°æ®è®­ç»ƒ")
        report_lines.append("  â€¢ çƒ­/æ¸©/å†·å·æŒ‰å‡ºç°é¢‘ç‡æ’åå‰/ä¸­/å33%åˆ’åˆ†")
        
        return "\n".join(report_lines)
    
    def load_model(self, model_type: str = "xgboost") -> Dict[str, Any]:
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        try:
            model_files = {
                'xgboost': 'xgboost_model.pkl',
                'lightgbm': 'lightgbm_model.pkl',
                'statistical': 'statistical_model.pkl'
            }
            
            if model_type not in model_files:
                logger.error(f"æœªçŸ¥çš„æ¨¡å‹ç±»å‹: {model_type}")
                return {'error': f'æœªçŸ¥çš„æ¨¡å‹ç±»å‹: {model_type}'}
            
            model_path = os.path.join(self.models_dir, model_files[model_type])
            
            if not os.path.exists(model_path):
                logger.error(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                return {'error': f'æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}'}
            
            with open(model_path, 'rb') as f:
                model_info = pickle.load(f)
            
            logger.info(f"åŠ è½½æ¨¡å‹æˆåŠŸ: {model_type}")
            return {'success': True, 'model_info': model_info}
            
        except Exception as e:
            logger.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def get_model_status(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹çŠ¶æ€"""
        model_status = {}
        
        for model_name in ['xgboost', 'lightgbm', 'statistical']:
            model_path = os.path.join(self.models_dir, f"{model_name}_model.pkl")
            
            if os.path.exists(model_path):
                try:
                    with open(model_path, 'rb') as f:
                        model_info = pickle.load(f)
                    
                    model_status[model_name] = {
                        'exists': True,
                        'size': os.path.getsize(model_path),
                        'modified': datetime.fromtimestamp(os.path.getmtime(model_path)),
                        'info': model_info.get('model_type', model_name),
                        'train_time': model_info.get('train_time', 'æœªçŸ¥')
                    }
                except Exception as e:
                    model_status[model_name] = {'exists': True, 'error': f'æ— æ³•è¯»å–: {str(e)}'}
            else:
                model_status[model_name] = {'exists': False}
        
        return model_status

# å…¨å±€æ¨¡å‹è®­ç»ƒæœåŠ¡å®ä¾‹
model_training_service = None

def get_model_training_service(db_path=None):
    """è·å–æ¨¡å‹è®­ç»ƒæœåŠ¡å®ä¾‹"""
    global model_training_service
    if model_training_service is None:
        model_training_service = ModelTrainingService(db_path)
    return model_training_service