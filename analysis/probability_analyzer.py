# analysis/probability_analyzer.py
"""
æ¦‚ç‡åˆ†æå™¨ - å¤šçª—å£æœŸå®é™…é‡å¤ç»Ÿè®¡
æŒ‰ç…§å…±è¯†æ–¹æ¡ˆï¼šåªæ˜¾ç¤ºç™¾åˆ†æ¯”ï¼Œä¸æ˜¾ç¤ºæ¬¡æ•°
"""
import logging
from typing import Dict, Any, Optional, List, Tuple, Union
from collections import Counter
from datetime import datetime
from utils.window_config import WindowConfigManager

from data.database import DoubleBallDatabase
from data.models import DoubleBallRecord

logger = logging.getLogger('probability_analyzer')

class ProbabilityAnalyzer:
    """æ¦‚ç‡åˆ†æå™¨ - ä½¿ç”¨ç³»ç»Ÿé…ç½®çš„çª—å£æœŸè¿›è¡Œå®é™…é‡å¤ç»Ÿè®¡"""
    
    def __init__(self, db: DoubleBallDatabase):
        self.db = db
        # ä»ç³»ç»Ÿé…ç½®è·å–çª—å£æœŸè®¾ç½®
        self.window_config = self._get_window_config()
        logger.debug(f"æ¦‚ç‡åˆ†æå™¨åˆå§‹åŒ–å®Œæˆï¼Œçª—å£é…ç½®: {self.window_config}")
    
    def _get_window_config(self) -> Dict[str, Optional[int]]:
        """è·å–çª—å£é…ç½®ï¼ˆåŸºäºç°æœ‰config.pyé…ç½®ï¼‰"""
        try:
            # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¾ªç¯ä¾èµ–
            from config import config
            
            return {
                'short_term': WindowConfigManager.get_window_by_name('short_term'),      # é»˜è®¤30æœŸ
                'medium_term': WindowConfigManager.get_window_by_name('short_term'),  # é»˜è®¤50æœŸ
                'long_term': WindowConfigManager.get_window_by_name('short_term'),          # é»˜è®¤100æœŸ
                'all_history': None  # å…¨éƒ¨å†å²
            }
        except ImportError as e:
            logger.warning(f"æ— æ³•å¯¼å…¥configæ¨¡å—ï¼Œä½¿ç”¨é»˜è®¤çª—å£é…ç½®: {e}")
            # å›é€€åˆ°é»˜è®¤å€¼ï¼ˆä¸config.pyé»˜è®¤å€¼ä¸€è‡´ï¼‰
            return {
                'short_term': 30,
                'medium_term': 50,
                'long_term': 100,
                'all_history': None
            }
    
    def analyze_current_period_probability(
        self, 
        current_record: Optional[DoubleBallRecord] = None,
        window_group: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        å¤šçª—å£æœŸæ¦‚ç‡åˆ†æ - åŸºäºå®é™…é‡å¤æ¬¡æ•°
        
        æŒ‰ç…§å…±è¯†æ–¹æ¡ˆï¼šåªè¿”å›ç™¾åˆ†æ¯”ï¼Œä¸è¿”å›æ¬¡æ•°
        """
        # éªŒè¯è¾“å…¥
        if not current_record:
            logger.warning("æ²¡æœ‰æä¾›å½“å‰æœŸæ•°æ®")
            return self._get_empty_result()
        
        # è·å–æ‰€æœ‰å†å²è®°å½•
        all_records = self.db.get_all_records()
        total_records = len(all_records)
        
        if total_records < 2:
            logger.warning(f"å†å²è®°å½•ä¸è¶³: {total_records} æ¡ï¼Œæ— æ³•è¿›è¡Œæ¦‚ç‡åˆ†æ")
            return self._get_empty_result(current_record)
        
        logger.info(f"å¼€å§‹æ¦‚ç‡åˆ†æ: å½“å‰æœŸ {current_record.issue}, æ€»è®°å½• {total_records} æ¡")
        
        # ç¡®å®šä½¿ç”¨çš„çª—å£ç»„
        if window_group is None:
            window_group = ['short_term', 'medium_term', 'long_term', 'all_history']
        
        # ä¸ºæ¯ä¸ªçª—å£æœŸè®¡ç®—åˆ†æ
        window_results = {}
        for window_name in window_group:
            if window_name not in self.window_config:
                logger.warning(f"æœªçŸ¥çª—å£ç±»å‹: {window_name}ï¼Œè·³è¿‡")
                continue
            
            window_result = self._analyze_single_window(
                window_name, current_record, all_records, total_records
            )
            
            if window_result:
                window_results[window_name] = window_result
        
        # ç»¼åˆæ‰€æœ‰çª—å£æœŸç»“æœ
        result = self._combine_window_results(
            window_results, current_record, total_records
        )
        
        logger.info(f"æ¦‚ç‡åˆ†æå®Œæˆï¼Œåˆ†æäº† {len(window_results)} ä¸ªçª—å£æœŸ")
        return result
    
    def _analyze_single_window(
        self,
        window_name: str,
        current_record: DoubleBallRecord,
        all_records: List[DoubleBallRecord],
        total_records: int
    ) -> Optional[Dict[str, Any]]:
        """åˆ†æå•ä¸ªçª—å£æœŸ"""
        period_limit = self.window_config[window_name]
        
        # è·å–è¯¥çª—å£æœŸçš„æ•°æ®
        if window_name == 'all_history' or period_limit is None:
            period_data = all_records
            effective_period = total_records
            logger.debug(f"çª—å£ '{window_name}': ä½¿ç”¨å…¨éƒ¨å†å²æ•°æ® ({effective_period} æ¡è®°å½•)")
        else:
            # ç¡®ä¿ä¸è¶…è¿‡æ€»è®°å½•æ•°
            effective_period = min(period_limit, total_records)
            period_data = all_records[-effective_period:]
            logger.debug(f"çª—å£ '{window_name}'(é…ç½®{period_limit}æœŸ): ä½¿ç”¨æœ€è¿‘{effective_period}æœŸæ•°æ®")
        
        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œåˆ†æ
        if len(period_data) < 2:
            logger.warning(f"çª—å£ '{window_name}' æ•°æ®ä¸è¶³ ({len(period_data)} æ¡)ï¼Œè·³è¿‡")
            return None
        
        # è®¡ç®—è¯¥çª—å£æœŸçš„å®é™…é‡å¤ç»Ÿè®¡
        return self._calculate_window_repeat_stats(
            window_name, current_record, period_data
        )
    
    def _calculate_window_repeat_stats(
        self,
        window_name: str,
        current_record: DoubleBallRecord,
        period_data: List[DoubleBallRecord]
    ) -> Dict[str, Any]:
        """
        è®¡ç®—å•ä¸ªçª—å£æœŸçš„å®é™…é‡å¤ç»Ÿè®¡
        æŒ‰ç…§å…±è¯†æ–¹æ¡ˆï¼šåªè¿”å›ç™¾åˆ†æ¯”ï¼Œä¸è¿”å›æ¬¡æ•°
        """
        current_reds = [current_record.red1, current_record.red2, current_record.red3,
                        current_record.red4, current_record.red5, current_record.red6]
        current_blue = current_record.blue
        
        # åˆå§‹åŒ–ç»Ÿè®¡
        repeat_counts = []  # æ¯æœŸçš„é‡å·æ•°é‡ (0-6)
        blue_repeat_counts = []  # æ¯æœŸè“çƒæ˜¯å¦é‡å¤ (0æˆ–1)
        
        logger.debug(f"è®¡ç®—çª—å£ '{window_name}' çš„é‡å¤ç»Ÿè®¡ï¼Œå…± {len(period_data)} æ¡è®°å½•")
        
        # ç»Ÿè®¡å†å²å®é™…é‡å¤æ¨¡å¼
        for i in range(len(period_data) - 1):
            record = period_data[i]
            next_record = period_data[i + 1]

            record_reds = [record.red1, record.red2, record.red3,
                           record.red4, record.red5, record.red6]
            next_reds = [next_record.red1, next_record.red2, next_record.red3,
                         next_record.red4, next_record.red5, next_record.red6]
            
            # å®é™…é‡å¤çš„çº¢çƒ
            repeat_reds = set(record_reds) & set(next_reds)
            repeat_count = len(repeat_reds)
            repeat_counts.append(repeat_count)
            
            # å®é™…é‡å¤çš„è“çƒ
            blue_repeat = 1 if record.blue == next_record.blue else 0
            blue_repeat_counts.append(blue_repeat)
        
        total_pairs = len(period_data) - 1
        
        # è®¡ç®—é‡å¤æ•°é‡çš„æ¦‚ç‡åˆ†å¸ƒï¼ˆæŒ‰ç…§å…±è¯†æ–¹æ¡ˆï¼šåªè¿”å›ç™¾åˆ†æ¯”ï¼‰
        repeat_prob_distribution = {}
        if total_pairs > 0:
            count_distribution = Counter(repeat_counts)
            for count in range(0, 7):  # ç¡®ä¿0åˆ°6éƒ½æœ‰å€¼
                freq = count_distribution.get(count, 0)
                repeat_prob_distribution[count] = freq / total_pairs  # ç›´æ¥è®¡ç®—ç™¾åˆ†æ¯”
        
        # è®¡ç®—è“çƒé‡å¤æ¦‚ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
        blue_repeat_probability = 0.0
        if total_pairs > 0:
            blue_repeat_probability = sum(blue_repeat_counts) / total_pairs
        
        # è®¡ç®—å½“å‰æœŸå·çš„é‡å¤é¢„æµ‹ï¼ˆåªè¿”å›ç™¾åˆ†æ¯”ï¼‰
        current_predictions = self._calculate_current_predictions(
            current_record, period_data
        )
        
        return {
            'window_name': window_name,
            'period_limit': self.window_config[window_name],
            'effective_periods': len(period_data),
            'total_pairs': total_pairs,
            
            # æ¦‚ç‡åˆ†å¸ƒï¼ˆæŒ‰ç…§å…±è¯†æ–¹æ¡ˆï¼šåªè¿”å›ç™¾åˆ†æ¯”ï¼‰
            'repeat_distribution': repeat_prob_distribution,  # ç™¾åˆ†æ¯”å½¢å¼
            'blue_repeat_probability': blue_repeat_probability,  # ç™¾åˆ†æ¯”å½¢å¼
            
            # å½“å‰æœŸé¢„æµ‹
            'current_predictions': current_predictions,
            
            # è°ƒè¯•ä¿¡æ¯
            'statistics_based_on_actual': True,
            'similarity_filter_applied': False,
            'analysis_timestamp': datetime.now().isoformat()
        }
    
    def _calculate_current_predictions(
        self,
        current_record: DoubleBallRecord,
        period_data: List[DoubleBallRecord]
    ) -> Dict[str, Any]:
        """è®¡ç®—å½“å‰æœŸå·çš„é‡å¤é¢„æµ‹ï¼ˆåªè¿”å›ç™¾åˆ†æ¯”ï¼‰"""
        current_reds = [current_record.red1, current_record.red2, current_record.red3,
                        current_record.red4, current_record.red5, current_record.red6]
        
        # ç»Ÿè®¡å†å²ä¸­ä¸å½“å‰æœŸç›¸ä¼¼çš„æƒ…å†µ
        similar_repeat_counts = []
        similar_blue_repeats = []
        red_repeat_predictions = {red: 0 for red in current_reds}
        
        total_comparisons = 0
        
        for i in range(len(period_data) - 1):
            record = period_data[i]
            next_record = period_data[i + 1]
            
            record_reds = [record.red1, record.red2, record.red3,
                           record.red4, record.red5, record.red6]
            
            # æ¯”è¾ƒå½“å‰æœŸä¸å†å²æœŸ
            common_reds = set(current_reds) & set(record_reds)
            
            if len(common_reds) > 0:  # åªè¦æœ‰å…±åŒå·ç å°±è€ƒè™‘
                total_comparisons += 1
                
                next_reds = [next_record.red1, next_record.red2, next_record.red3,
                             next_record.red4, next_record.red5, next_record.red6]
                
                # è®°å½•é‡å¤æƒ…å†µ
                repeat_reds = set(record_reds) & set(next_reds)
                repeat_count = len(repeat_reds)
                similar_repeat_counts.append(repeat_count)
                
                # è“çƒé‡å¤
                blue_repeat = 1 if record.blue == next_record.blue else 0
                similar_blue_repeats.append(blue_repeat)
                
                # é¢„æµ‹æ¯ä¸ªçº¢çƒçš„é‡å¤
                for red in current_reds:
                    if red in repeat_reds:
                        red_repeat_predictions[red] += 1
        
        # è®¡ç®—é¢„æµ‹æ¦‚ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
        if total_comparisons > 0:
            # å¹³å‡é‡å¤æ•°é‡
            avg_repeat_count = sum(similar_repeat_counts) / total_comparisons if similar_repeat_counts else 0
            
            # çº¢çƒé‡å¤æ¦‚ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
            red_probabilities = {
                red: count / total_comparisons 
                for red, count in red_repeat_predictions.items()
            }
            
            # è“çƒé‡å¤æ¦‚ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
            blue_repeat_prob = sum(similar_blue_repeats) / total_comparisons if similar_blue_repeats else 0
        else:
            avg_repeat_count = 0
            red_probabilities = {red: 0 for red in current_reds}
            blue_repeat_prob = 0
        
        return {
            'based_on_comparisons': total_comparisons,
            'avg_repeat_count': avg_repeat_count,
            'red_probabilities': red_probabilities,
            'blue_repeat_probability': blue_repeat_prob
        }
    
    def _combine_window_results(
        self,
        window_results: Dict[str, Dict[str, Any]],
        current_record: DoubleBallRecord,
        total_records: int
    ) -> Dict[str, Any]:
        """ç»¼åˆæ‰€æœ‰çª—å£æœŸç»“æœ"""
        current_reds = [current_record.red1, current_record.red2, current_record.red3,
                        current_record.red4, current_record.red5, current_record.red6]
        current_blue = current_record.blue
        
        # æ”¶é›†è¶‹åŠ¿åˆ†ææ•°æ®
        trends_analysis = self._analyze_repeat_trends(window_results)
        
        return {
            'current_period': current_record.issue,
            'current_reds': current_reds,
            'current_blue': current_blue,
            'total_records': total_records,
            
            # å¤šçª—å£æœŸåˆ†æç»“æœ
            'window_analysis': window_results,
            
            # è¶‹åŠ¿åˆ†æç»“æœ
            'trends_analysis': trends_analysis,
            
            # ç»¼åˆé¢„æµ‹ï¼ˆåŸºäºé•¿æœŸçª—å£ï¼‰
            'comprehensive_predictions': self._get_comprehensive_predictions(window_results),
            
            # è°ƒè¯•ä¿¡æ¯
            'analysis_method': 'multi_window_actual_repeat',
            'similarity_filter_applied': False,
            'windows_analyzed': list(window_results.keys()),
            'analysis_time': datetime.now().isoformat(),
            'window_config_used': self.window_config
        }
    
    def _analyze_repeat_trends(self, window_results: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æé‡å·åˆ†å¸ƒçš„è·¨çª—å£è¶‹åŠ¿"""
        trends = {}
        
        # å®šä¹‰çª—å£æœŸé¡ºåº
        window_order = ['short_term', 'medium_term', 'long_term', 'all_history']
        
        # æ”¶é›†æ¯ä¸ªé‡å¤æ•°é‡åœ¨å››ä¸ªçª—å£æœŸçš„æ¦‚ç‡
        for repeat_count in range(0, 7):
            count_trends = {}
            
            for window_name in window_order:
                if window_name in window_results:
                    window_data = window_results[window_name]
                    repeat_dist = window_data.get('repeat_distribution', {})
                    prob = repeat_dist.get(repeat_count, 0.0)
                    count_trends[window_name] = prob
            
            if count_trends:
                # åˆ¤æ–­è¶‹åŠ¿
                trend_type = self._determine_trend_type(count_trends, window_order)
                trends[repeat_count] = {
                    'probabilities': count_trends,
                    'trend': trend_type
                }
        
        # æ‰¾å‡ºæœ€å¯èƒ½çš„é‡å·æ•°é‡ï¼ˆåŸºäºé•¿æœŸçª—å£ï¼‰
        most_likely = 0
        max_prob = 0.0
        
        if 'long_term' in window_results:
            long_term_dist = window_results['long_term'].get('repeat_distribution', {})
            for count, prob in long_term_dist.items():
                if prob > max_prob:
                    max_prob = prob
                    most_likely = count
        
        return {
            'repeat_trends': trends,
            'most_likely_repeat_count': most_likely,
            'trend_summary': self._generate_trend_summary(trends, most_likely)
        }
    
    def _determine_trend_type(self, probabilities: Dict[str, float], window_order: List[str]) -> str:
        """åˆ¤æ–­è¶‹åŠ¿ç±»å‹"""
        if len(probabilities) < 2:
            return "æ•°æ®ä¸è¶³"
        
        values = [probabilities.get(window, 0.0) for window in window_order if window in probabilities]
        
        # æ£€æŸ¥æ˜¯å¦é€’å¢
        is_increasing = all(values[i] <= values[i+1] for i in range(len(values)-1))
        # æ£€æŸ¥æ˜¯å¦é€’å‡
        is_decreasing = all(values[i] >= values[i+1] for i in range(len(values)-1))
        
        # è®¡ç®—æœ€å¤§å·®å¼‚
        max_diff = max(values) - min(values) if values else 0
        
        if len(values) == 4:
            if is_increasing and max_diff > 0.02:  # å·®å¼‚å¤§äº2%æ‰è®¤ä¸ºæ˜¯æ˜æ˜¾è¶‹åŠ¿
                return "é€’å¢"
            elif is_decreasing and max_diff > 0.02:
                return "é€’å‡"
            elif max_diff <= 0.02:
                return "ç¨³å®š"
            else:
                return "æ³¢åŠ¨"
        else:
            return "æ•°æ®ä¸å®Œæ•´"
    
    def _generate_trend_summary(self, trends: Dict[int, Dict[str, Any]], most_likely: int) -> str:
        """ç”Ÿæˆè¶‹åŠ¿æ€»ç»“æ–‡æœ¬"""
        if not trends:
            return "è¶‹åŠ¿åˆ†ææ•°æ®ä¸è¶³"
        
        summary_lines = []
        
        # æ·»åŠ æœ€å¯èƒ½é‡å·æ•°é‡
        summary_lines.append(f"æœ€å¯èƒ½é‡å¤æ•°é‡: {most_likely}ä¸ªçº¢çƒ")
        
        # åˆ†ææ¯ä¸ªé‡å·æ•°é‡çš„è¶‹åŠ¿
        for count in range(0, 7):
            if count in trends:
                trend_data = trends[count]
                probabilities = trend_data['probabilities']
                trend = trend_data['trend']
                
                # åªæ˜¾ç¤ºæœ‰æ„ä¹‰çš„è¶‹åŠ¿
                if probabilities.get('long_term', 0) > 0.01 or trend != "ç¨³å®š":  # æ¦‚ç‡å¤§äº1%æˆ–è¶‹åŠ¿æ˜æ˜¾
                    probs_str = " â†’ ".join([f"{probabilities.get(w, 0):.1%}" 
                                           for w in ['short_term', 'medium_term', 'long_term', 'all_history'] 
                                           if w in probabilities])
                    summary_lines.append(f"é‡å¤{count}ä¸ª: {probs_str} ({trend})")
        
        return "\n".join(summary_lines)
    
    def _get_comprehensive_predictions(self, window_results: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """è·å–ç»¼åˆé¢„æµ‹ç»“æœ"""
        # ä¼˜å…ˆä½¿ç”¨é•¿æœŸçª—å£
        if 'long_term' in window_results:
            long_term = window_results['long_term']
            return {
                'repeat_distribution': long_term.get('repeat_distribution', {}),
                'blue_repeat_probability': long_term.get('blue_repeat_probability', 0),
                'window_source': 'long_term',
                'window_display_name': 'é•¿æœŸçª—å£'
            }
        elif window_results:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„çª—å£
            first_window = next(iter(window_results.values()))
            first_window_name = next(iter(window_results.keys()))
            return {
                'repeat_distribution': first_window.get('repeat_distribution', {}),
                'blue_repeat_probability': first_window.get('blue_repeat_probability', 0),
                'window_source': first_window_name,
                'window_display_name': self._get_window_display_name(first_window_name)
            }
        
        return {}
    
    def _get_window_display_name(self, window_name: str) -> str:
        """è·å–çª—å£çš„æ˜¾ç¤ºåç§°"""
        names = {
            'short_term': 'çŸ­æœŸ',
            'medium_term': 'ä¸­æœŸ',
            'long_term': 'é•¿æœŸ',
            'all_history': 'å…¨éƒ¨å†å²'
        }
        return names.get(window_name, window_name)
    
    def _get_empty_result(
        self, 
        current_record: Optional[DoubleBallRecord] = None
    ) -> Dict[str, Any]:
        """è·å–ç©ºç»“æœ"""
        result = {
            'error': 'æ•°æ®ä¸è¶³æˆ–æ— å½“å‰æœŸæ•°æ®',
            'window_analysis': {},
            'analysis_time': datetime.now().isoformat()
        }
        
        if current_record:
            result.update({
                'current_period': current_record.issue,
                'current_reds': [current_record.red1, current_record.red2, current_record.red3,
                                current_record.red4, current_record.red5, current_record.red6],
                'current_blue': current_record.blue
            })
        
        return result
    
    def generate_probability_report(self, analysis_result: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ¦‚ç‡åˆ†ææŠ¥å‘Š - æ”¯æŒå¤šçª—å£æœŸè¶‹åŠ¿åˆ†æ"""
        report_lines = []
        report_lines.append("=" * 60)
        report_lines.append("åŒè‰²çƒæ¦‚ç‡åˆ†ææŠ¥å‘Š (å¤šçª—å£æœŸè¶‹åŠ¿åˆ†æ)")
        report_lines.append("=" * 60)
        report_lines.append(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append(f"å½“å‰æœŸå·: {analysis_result.get('current_period', 'æœªçŸ¥')}")
        report_lines.append(f"å½“å‰çº¢çƒ: {analysis_result.get('current_reds', [])}")
        report_lines.append(f"å½“å‰è“çƒ: {analysis_result.get('current_blue', 0)}")
        report_lines.append(f"æ€»è®°å½•æ•°: {analysis_result.get('total_records', 0)}")
        
        # å¤šçª—å£æœŸåˆ†æç»“æœ
        window_analysis = analysis_result.get('window_analysis', {})
        if window_analysis:
            report_lines.append("\n" + "=" * 60)
            report_lines.append("å¤šçª—å£æœŸé‡å·æ¦‚ç‡åˆ†å¸ƒ")
            report_lines.append("=" * 60)
            
            # æ˜¾ç¤ºæ¯ä¸ªçª—å£æœŸçš„é‡å·åˆ†å¸ƒ
            window_display_order = [
                ('short_term', 'ğŸ“± çŸ­æœŸçª—å£'),
                ('medium_term', 'ğŸ“Š ä¸­æœŸçª—å£'), 
                ('long_term', 'ğŸ“ˆ é•¿æœŸçª—å£'),
                ('all_history', 'ğŸ“š å…¨éƒ¨å†å²')
            ]
            
            for window_key, window_title in window_display_order:
                if window_key in window_analysis:
                    window_data = window_analysis[window_key]
                    period_limit = window_data.get('period_limit', 'å…¨éƒ¨')
                    effective_periods = window_data.get('effective_periods', 0)
                    total_pairs = window_data.get('total_pairs', 0)
                    
                    # è·å–çª—å£æœŸæè¿°
                    window_desc = {
                        'short_term': f'æœ€è¿‘{period_limit}æœŸ' if period_limit else 'å…¨éƒ¨å†å²',
                        'medium_term': f'æœ€è¿‘{period_limit}æœŸ' if period_limit else 'å…¨éƒ¨å†å²',
                        'long_term': f'æœ€è¿‘{period_limit}æœŸ' if period_limit else 'å…¨éƒ¨å†å²',
                        'all_history': 'å…¨éƒ¨å†å²æ•°æ®'
                    }.get(window_key, '')
                    
                    report_lines.append(f"\n{window_title} ({window_desc}):")
                    report_lines.append(f"  ç»Ÿè®¡åŸºæ•°: {effective_periods}æœŸæ•°æ®ï¼Œ{total_pairs}ä¸ªç›¸é‚»æœŸå¯¹")
                    
                    # é‡å·åˆ†å¸ƒï¼ˆæŒ‰ç…§å…±è¯†æ–¹æ¡ˆï¼šåªæ˜¾ç¤ºç™¾åˆ†æ¯”ï¼‰
                    repeat_dist = window_data.get('repeat_distribution', {})
                    if repeat_dist:
                        report_lines.append("  é‡å·æ•°é‡æ¦‚ç‡åˆ†å¸ƒ:")
                        for count in range(0, 7):
                            prob = repeat_dist.get(count, 0.0)
                            report_lines.append(f"    é‡å¤{count}ä¸ªçº¢çƒ: {prob:.2%}")
                    
                    # è“çƒé‡å¤æ¦‚ç‡
                    blue_prob = window_data.get('blue_repeat_probability', 0)
                    report_lines.append(f"  è“çƒé‡å¤æ¦‚ç‡: {blue_prob:.2%}")
        
        # è¶‹åŠ¿åˆ†æ
        trends_analysis = analysis_result.get('trends_analysis', {})
        if trends_analysis:
            report_lines.append("\n" + "=" * 60)
            report_lines.append("ğŸ¯ é‡å·åˆ†å¸ƒè¶‹åŠ¿åˆ†æ")
            report_lines.append("=" * 60)
            
            repeat_trends = trends_analysis.get('repeat_trends', {})
            most_likely = trends_analysis.get('most_likely_repeat_count', 0)
            trend_summary = trends_analysis.get('trend_summary', '')
            
            report_lines.append(f"\næœ€å¯èƒ½é‡å¤æ•°é‡: {most_likely}ä¸ªçº¢çƒ")
            report_lines.append("\nè·¨çª—å£æœŸè¶‹åŠ¿åˆ†æ:")
            
            for count in range(0, 7):
                if count in repeat_trends:
                    trend_data = repeat_trends[count]
                    probabilities = trend_data['probabilities']
                    trend = trend_data['trend']
                    
                    # è·å–å››ä¸ªçª—å£æœŸçš„æ¦‚ç‡
                    short_prob = probabilities.get('short_term', 0.0)
                    medium_prob = probabilities.get('medium_term', 0.0)
                    long_prob = probabilities.get('long_term', 0.0)
                    all_prob = probabilities.get('all_history', 0.0)
                    
                    # åªæ˜¾ç¤ºæœ‰æ„ä¹‰çš„è¶‹åŠ¿
                    if long_prob > 0.01 or trend != "ç¨³å®š":
                        report_lines.append(f"  é‡å¤{count}ä¸ªçº¢çƒ:")
                        report_lines.append(f"    çŸ­æœŸ({short_prob:.1%}) â†’ ä¸­æœŸ({medium_prob:.1%}) â†’ é•¿æœŸ({long_prob:.1%}) â†’ å…¨éƒ¨({all_prob:.1%})")
                        report_lines.append(f"    è¶‹åŠ¿åˆ¤æ–­: {trend}")
            
            if trend_summary:
                report_lines.append(f"\nè¶‹åŠ¿æ€»ç»“:\n{trend_summary}")
        
        # ç»¼åˆé¢„æµ‹
        comprehensive = analysis_result.get('comprehensive_predictions', {})
        if comprehensive:
            report_lines.append("\n" + "=" * 60)
            report_lines.append("ğŸ’¡ ç»¼åˆé¢„æµ‹å»ºè®® (åŸºäºé•¿æœŸçª—å£)")
            report_lines.append("=" * 60)
            
            window_source = comprehensive.get('window_source', 'æœªçŸ¥')
            window_display = comprehensive.get('window_display_name', 'æœªçŸ¥')
            
            repeat_dist = comprehensive.get('repeat_distribution', {})
            if repeat_dist:
                report_lines.append(f"\n{window_display}é‡å·åˆ†å¸ƒ:")
                for count in range(0, 7):
                    prob = repeat_dist.get(count, 0.0)
                    if prob > 0:
                        report_lines.append(f"  é‡å¤{count}ä¸ªçº¢çƒ: {prob:.2%}")
                
                # æ‰¾å‡ºæœ€é«˜æ¦‚ç‡çš„é‡å·æ•°é‡
                max_prob = 0
                best_count = 0
                for count, prob in repeat_dist.items():
                    if prob > max_prob:
                        max_prob = prob
                        best_count = count
                
                if max_prob > 0:
                    report_lines.append(f"\nğŸ¯ é¢„æµ‹å»ºè®®:")
                    report_lines.append(f"  æœ€å¯èƒ½é‡å¤: {best_count}ä¸ªçº¢çƒ (æ¦‚ç‡: {max_prob:.2%})")
                    
                    # æ ¹æ®æ¦‚ç‡ç»™å‡ºå»ºè®®
                    if best_count <= 1:
                        report_lines.append(f"  å»ºè®®: é‡ç‚¹å…³æ³¨0-1ä¸ªé‡å·çš„æƒ…å†µ")
                    elif best_count <= 3:
                        report_lines.append(f"  å»ºè®®: é‡ç‚¹å…³æ³¨{best_count-1}-{best_count+1}ä¸ªé‡å·çš„èŒƒå›´")
                    else:
                        report_lines.append(f"  å»ºè®®: é‡å·è¾ƒå¤šï¼Œéœ€è°¨æ…é€‰æ‹©")
            
            # è“çƒé‡å¤æ¦‚ç‡
            blue_prob = comprehensive.get('blue_repeat_probability', 0)
            report_lines.append(f"\nğŸ”µ è“çƒé‡å¤æ¦‚ç‡: {blue_prob:.2%}")
            if blue_prob < 0.05:
                report_lines.append("  å»ºè®®: è“çƒé‡å¤æ¦‚ç‡è¾ƒä½ï¼Œä¸å»ºè®®é€‰æ‹©ä¸ŠæœŸè“çƒ")
            elif blue_prob < 0.1:
                report_lines.append("  å»ºè®®: è“çƒé‡å¤æ¦‚ç‡ä¸€èˆ¬ï¼Œå¯é€‚å½“è€ƒè™‘")
            else:
                report_lines.append("  å»ºè®®: è“çƒé‡å¤æ¦‚ç‡è¾ƒé«˜ï¼Œå€¼å¾—å…³æ³¨")
        
        # è°ƒè¯•ä¿¡æ¯
        debug_info = {
            'åˆ†ææ¨¡å¼': 'å¤šçª—å£æœŸå®é™…é‡å¤ç»Ÿè®¡',
            'ç›¸ä¼¼åº¦ç­›é€‰': 'æœªä½¿ç”¨',
            'ç»Ÿè®¡æ–¹æ³•': 'åŸºäºå®é™…å‘ç”Ÿçš„é‡å¤æ¬¡æ•°',
            'æ•°æ®æ¥æº': 'å…¨éƒ¨å†å²æ•°æ®åˆ†çª—å£ç»Ÿè®¡'
        }
        
        report_lines.append("\n" + "=" * 60)
        report_lines.append("åˆ†æè¯´æ˜")
        report_lines.append("=" * 60)
        for key, value in debug_info.items():
            report_lines.append(f"  {key}: {value}")
        
        return "\n".join(report_lines)
    
    def _calculate_similarity(self, list1: List[int], list2: List[int]) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªåˆ—è¡¨çš„ç›¸ä¼¼åº¦ï¼ˆä¿ç•™æ–¹æ³•ä»¥å…¼å®¹ï¼Œä½†ä¸å†ä½¿ç”¨ï¼‰
        ç°åœ¨åŸºäºå®é™…é‡å¤ç»Ÿè®¡ï¼Œä¸è¿›è¡Œç›¸ä¼¼åº¦ç­›é€‰
        """
        # æ­¤æ–¹æ³•ä¿ç•™ä½†ä¸ä¸»åŠ¨ä½¿ç”¨
        set1 = set(list1)
        set2 = set(list2)
        return len(set1 & set2) / len(set1 | set2) if len(set1 | set2) > 0 else 0