# train_ml_model.py
"""
è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹ - é›†æˆé…ç½®ç³»ç»Ÿ
"""
import sys
import os
import logging
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('ml_trainer')

def check_ml_dependencies():
    """æ£€æŸ¥MLä¾èµ–"""
    print("ğŸ” æ£€æŸ¥æœºå™¨å­¦ä¹ ä¾èµ–...")
    
    required_libs = {
        'numpy': 'ç”¨äºæ•°å€¼è®¡ç®—',
        'pandas': 'ç”¨äºæ•°æ®å¤„ç†',
        'scikit-learn': 'ç”¨äºæœºå™¨å­¦ä¹ ç®—æ³•',
        'xgboost': 'ç”¨äºXGBoostç®—æ³•ï¼ˆå¯é€‰ï¼‰',
        'lightgbm': 'ç”¨äºLightGBMç®—æ³•ï¼ˆå¯é€‰ï¼‰'
    }
    
    missing = []
    installed = []
    
    for lib, desc in required_libs.items():
        try:
            __import__(lib)
            installed.append((lib, desc))
            print(f"  âœ… {lib:15} - {desc}")
        except ImportError:
            if lib in ['xgboost', 'lightgbm']:
                print(f"  âš ï¸  {lib:15} - {desc} (å¯é€‰)")
            else:
                missing.append(lib)
                print(f"  âŒ {lib:15} - {desc}")
    
    if missing:
        print(f"\nâš ï¸  ç¼ºå°‘å¿…è¦ä¾èµ–: {missing}")
        print("å®‰è£…å‘½ä»¤:")
        print(f"  pip install {' '.join(missing)}")
        return False
    
    print(f"\nâœ… æ‰€æœ‰ä¾èµ–å·²å®‰è£… ({len(installed)}/{len(required_libs)})")
    return True

def train_ml_models():
    """è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹"""
    print("\nğŸ¤– å¼€å§‹è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹...")
    
    try:
        # 1. å¯¼å…¥é…ç½®
        from config import config
        print(f"ğŸ“‹ ä½¿ç”¨é…ç½®: {config.system.APP_NAME} v{config.system.VERSION}")
        
        # è·å–é…ç½®å‚æ•°
        train_window = config.prediction.FEATURE_WINDOW  # ä»predictioné…ç½®è·å–
        train_test_ratio = config.prediction.TRAIN_TEST_SPLIT
        random_state = 42
        
        print(f"ğŸ“Š è®­ç»ƒçª—å£: {train_window}æœŸ")
        print(f"ğŸ“ˆ è®­ç»ƒæµ‹è¯•æ¯”ä¾‹: {train_test_ratio}")
        
        # 2. å¯¼å…¥æ•°æ®åº“
        from utils.db_manager import DatabaseManager
        db_manager = DatabaseManager()
        db = db_manager.get_db()
        
        # è·å–æ•°æ®
        total_records = db.get_record_count()
        print(f"ğŸ“ æ•°æ®åº“è®°å½•: {total_records}æœŸ")
        
        if total_records < train_window * 2:
            print(f"âš ï¸  æ•°æ®é‡ä¸è¶³ï¼Œéœ€è¦è‡³å°‘ {train_window * 2} æœŸæ•°æ®")
            return False
        
        # è·å–è®­ç»ƒæ•°æ®
        records = db.get_recent_records(train_window * 2)  # è·å–åŒå€æ•°æ®
        print(f"ğŸ“Š ä½¿ç”¨ {len(records)} æœŸæ•°æ®è¿›è¡Œè®­ç»ƒ")
        
        # 3. å‡†å¤‡ç‰¹å¾å·¥ç¨‹
        print("\nğŸ”§ å‡†å¤‡ç‰¹å¾...")
        features, labels = prepare_features(records, train_window)
        
        if len(features) < 50:
            print("âš ï¸  æœ‰æ•ˆç‰¹å¾æ•°æ®ä¸è¶³")
            return False
        
        # 4. è®­ç»ƒå„ç§æ¨¡å‹
        results = {}
        
        # éšæœºæ£®æ—
        if 'sklearn' in sys.modules:
            results['random_forest'] = train_random_forest(features, labels, train_test_ratio, random_state)
        
        # XGBoost
        if 'xgboost' in sys.modules:
            results['xgboost'] = train_xgboost(features, labels, train_test_ratio, random_state)
        
        # LightGBM
        if 'lightgbm' in sys.modules:
            results['lightgbm'] = train_lightgbm(features, labels, train_test_ratio, random_state)
        
        # 5. ä¿å­˜æ¨¡å‹
        print("\nğŸ’¾ ä¿å­˜æ¨¡å‹...")
        save_models(results)
        
        # 6. æ›´æ–°é…ç½®
        update_model_config(results)
        
        return True
        
    except Exception as e:
        logger.error(f"è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def prepare_features(records, window_size):
    """å‡†å¤‡ç‰¹å¾æ•°æ®"""
    import numpy as np
    
    features = []
    labels_red = []
    labels_blue = []
    
    for i in range(window_size, len(records)):
        # ä½¿ç”¨å‰window_sizeæœŸæ•°æ®é¢„æµ‹ä¸‹ä¸€æœŸ
        window_records = records[i-window_size:i]
        next_record = records[i]
        
        # ç‰¹å¾ï¼šç»Ÿè®¡ç‰¹å¾
        feature_vector = []
        
        # 1. åŸºç¡€ç»Ÿè®¡ç‰¹å¾
        all_reds = []
        all_blues = []
        
        for record in window_records:
            all_reds.extend(record['red_balls'])
            all_blues.append(record['blue_ball'])
        
        # çº¢çƒé¢‘ç‡
        red_counts = {}
        for red in all_reds:
            red_counts[red] = red_counts.get(red, 0) + 1
        
        # æ·»åŠ çº¢çƒé¢‘ç‡ç‰¹å¾
        for red in range(1, 34):
            feature_vector.append(red_counts.get(red, 0) / len(window_records))
        
        # è“çƒé¢‘ç‡
        blue_counts = {}
        for blue in all_blues:
            blue_counts[blue] = blue_counts.get(blue, 0) + 1
        
        # æ·»åŠ è“çƒé¢‘ç‡ç‰¹å¾
        for blue in range(1, 17):
            feature_vector.append(blue_counts.get(blue, 0) / len(window_records))
        
        # 2. æœ€è¿‘ä¸€æœŸç‰¹å¾
        latest = window_records[-1]
        latest_reds = latest['red_balls']
        latest_blue = latest['blue_ball']
        
        feature_vector.extend([
            sum(latest_reds),  # å’Œå€¼
            max(latest_reds) - min(latest_reds),  # è·¨åº¦
            len([x for x in latest_reds if x <= 11]),  # å°å·æ•°é‡
            len([x for x in latest_reds if x % 2 == 0]),  # å¶æ•°æ•°é‡
            latest_blue,
            latest_blue % 2  # è“çƒå¥‡å¶
        ])
        
        features.append(feature_vector)
        
        # æ ‡ç­¾ï¼šä¸‹ä¸€æœŸçš„çº¢çƒï¼ˆç¬¬ä¸€ä¸ªï¼‰å’Œè“çƒ
        labels_red.append(next_record['red_balls'][0])
        labels_blue.append(next_record['blue_ball'])
    
    return np.array(features), {
        'red': np.array(labels_red),
        'blue': np.array(labels_blue)
    }

def train_random_forest(features, labels, test_ratio, random_state):
    """è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹"""
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.model_selection import train_test_split
    
    print("ğŸŒ² è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹...")
    
    # çº¢çƒé¢„æµ‹
    X_train, X_test, y_train, y_test = train_test_split(
        features, labels['red'], test_size=test_ratio, random_state=random_state
    )
    
    model_red = RandomForestClassifier(n_estimators=100, random_state=random_state)
    model_red.fit(X_train, y_train)
    
    accuracy_red = model_red.score(X_test, y_test)
    
    # è“çƒé¢„æµ‹
    X_train, X_test, y_train, y_test = train_test_split(
        features, labels['blue'], test_size=test_ratio, random_state=random_state
    )
    
    model_blue = RandomForestClassifier(n_estimators=100, random_state=random_state)
    model_blue.fit(X_train, y_train)
    
    accuracy_blue = model_blue.score(X_test, y_test)
    
    print(f"  âœ… çº¢çƒå‡†ç¡®ç‡: {accuracy_red:.3f}")
    print(f"  âœ… è“çƒå‡†ç¡®ç‡: {accuracy_blue:.3f}")
    
    return {
        'model_red': model_red,
        'model_blue': model_blue,
        'accuracy_red': accuracy_red,
        'accuracy_blue': accuracy_blue,
        'feature_count': features.shape[1]
    }

def train_xgboost(features, labels, test_ratio, random_state):
    """è®­ç»ƒXGBoostæ¨¡å‹"""
    try:
        import xgboost as xgb
        from sklearn.model_selection import train_test_split
        
        print("âš¡ è®­ç»ƒXGBoostæ¨¡å‹...")
        
        # çº¢çƒé¢„æµ‹
        X_train, X_test, y_train, y_test = train_test_split(
            features, labels['red'], test_size=test_ratio, random_state=random_state
        )
        
        model_red = xgb.XGBClassifier(n_estimators=100, random_state=random_state)
        model_red.fit(X_train, y_train)
        
        accuracy_red = model_red.score(X_test, y_test)
        
        # è“çƒé¢„æµ‹
        X_train, X_test, y_train, y_test = train_test_split(
            features, labels['blue'], test_size=test_ratio, random_state=random_state
        )
        
        model_blue = xgb.XGBClassifier(n_estimators=100, random_state=random_state)
        model_blue.fit(X_train, y_train)
        
        accuracy_blue = model_blue.score(X_test, y_test)
        
        print(f"  âœ… çº¢çƒå‡†ç¡®ç‡: {accuracy_red:.3f}")
        print(f"  âœ… è“çƒå‡†ç¡®ç‡: {accuracy_blue:.3f}")
        
        return {
            'model_red': model_red,
            'model_blue': model_blue,
            'accuracy_red': accuracy_red,
            'accuracy_blue': accuracy_blue
        }
    except Exception as e:
        print(f"  âš ï¸  XGBoostè®­ç»ƒå¤±è´¥: {e}")
        return None

def train_lightgbm(features, labels, test_ratio, random_state):
    """è®­ç»ƒLightGBMæ¨¡å‹"""
    try:
        import lightgbm as lgb
        from sklearn.model_selection import train_test_split
        
        print("ğŸ’¡ è®­ç»ƒLightGBMæ¨¡å‹...")
        
        # çº¢çƒé¢„æµ‹
        X_train, X_test, y_train, y_test = train_test_split(
            features, labels['red'], test_size=test_ratio, random_state=random_state
        )
        
        model_red = lgb.LGBMClassifier(n_estimators=100, random_state=random_state)
        model_red.fit(X_train, y_train)
        
        accuracy_red = model_red.score(X_test, y_test)
        
        # è“çƒé¢„æµ‹
        X_train, X_test, y_train, y_test = train_test_split(
            features, labels['blue'], test_size=test_ratio, random_state=random_state
        )
        
        model_blue = lgb.LGBMClassifier(n_estimators=100, random_state=random_state)
        model_blue.fit(X_train, y_train)
        
        accuracy_blue = model_blue.score(X_test, y_test)
        
        print(f"  âœ… çº¢çƒå‡†ç¡®ç‡: {accuracy_red:.3f}")
        print(f"  âœ… è“çƒå‡†ç¡®ç‡: {accuracy_blue:.3f}")
        
        return {
            'model_red': model_red,
            'model_blue': model_blue,
            'accuracy_red': accuracy_red,
            'accuracy_blue': accuracy_blue
        }
    except Exception as e:
        print(f"  âš ï¸  LightGBMè®­ç»ƒå¤±è´¥: {e}")
        return None

def save_models(results):
    """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
    import pickle
    import json
    
    os.makedirs('models', exist_ok=True)
    
    model_info = {
        'trained_at': datetime.now().isoformat(),
        'models': {}
    }
    
    for model_name, result in results.items():
        if result is None:
            continue
            
        # ä¿å­˜æ¨¡å‹æ–‡ä»¶
        model_path = os.path.join('models', f'{model_name}_model.pkl')
        with open(model_path, 'wb') as f:
            pickle.dump(result, f)
        
        # è®°å½•æ¨¡å‹ä¿¡æ¯
        model_info['models'][model_name] = {
            'accuracy_red': float(result.get('accuracy_red', 0)),
            'accuracy_blue': float(result.get('accuracy_blue', 0)),
            'feature_count': result.get('feature_count', 0),
            'model_file': f'{model_name}_model.pkl'
        }
        
        print(f"  ğŸ’¾ {model_name:15} å·²ä¿å­˜")
    
    # ä¿å­˜æ¨¡å‹å…ƒæ•°æ®
    metadata_path = os.path.join('models', 'model_metadata.json')
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(model_info, f, indent=2, ensure_ascii=False)
    
    print(f"  ğŸ“„ æ¨¡å‹å…ƒæ•°æ®å·²ä¿å­˜")

def update_model_config(results):
    """æ›´æ–°æ¨¡å‹é…ç½®"""
    try:
        from config import config
        
        # æ‰¾åˆ°æœ€ä½³æ¨¡å‹
        best_model = None
        best_accuracy = 0
        
        for model_name, result in results.items():
            if result and 'accuracy_red' in result:
                accuracy = result['accuracy_red']
                if accuracy > best_accuracy:
                    best_accuracy = accuracy
                    best_model = model_name
        
        if best_model:
            print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model} (å‡†ç¡®ç‡: {best_accuracy:.3f})")
            
            # è¿™é‡Œå¯ä»¥æ›´æ–°é…ç½®ï¼Œä½†configå¯èƒ½æ˜¯åªè¯»çš„
            # æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå•ç‹¬çš„é…ç½®æ–‡ä»¶
            config_data = {
                'best_model': best_model,
                'best_accuracy': best_accuracy,
                'last_trained': datetime.now().isoformat()
            }
            
            config_path = os.path.join('models', 'ml_config.json')
            import json
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, indent=2, ensure_ascii=False)
            
            print(f"  ğŸ“‹ MLé…ç½®å·²æ›´æ–°: {config_path}")
    except Exception as e:
        print(f"  âš ï¸  æ›´æ–°é…ç½®å¤±è´¥: {e}")

if __name__ == "__main__":
    from datetime import datetime
    
    print("=" * 60)
    print("ğŸ¤– åŒè‰²çƒæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒ (é›†æˆé…ç½®ç‰ˆ)")
    print("=" * 60)
    
    # æ£€æŸ¥ä¾èµ–
    if not check_ml_dependencies():
        print("\nâŒ è¯·å…ˆå®‰è£…ç¼ºå¤±çš„ä¾èµ–")
        sys.exit(1)
    
    # è®­ç»ƒæ¨¡å‹
    success = train_ml_models()
    
    print("\n" + "=" * 60)
    if success:
        print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
        print("\nä¸‹ä¸€æ­¥:")
        print("1. è¿è¡Œ python test_ml.py æµ‹è¯•MLé¢„æµ‹")
        print("2. åœ¨ prediction_service.py ä¸­å¯ç”¨MLé¢„æµ‹")
        print("3. æŸ¥çœ‹ models/ ç›®å½•ä¸­çš„æ¨¡å‹æ–‡ä»¶")
    else:
        print("âŒ è®­ç»ƒå¤±è´¥")
        print("\nå¯èƒ½çš„åŸå› :")
        print("1. æ•°æ®é‡ä¸è¶³")
        print("2. ç‰¹å¾å·¥ç¨‹å¤±è´¥")
        print("3. æ¨¡å‹è®­ç»ƒé”™è¯¯")
    
    print("=" * 60)